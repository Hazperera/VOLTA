<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>graphAlgorithms.multiplex.build_network API documentation</title>
<meta name="description" content="contains functions to create single and flat multilayer networks build on networkx â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>graphAlgorithms.multiplex.build_network</code></h1>
</header>
<section id="section-intro">
<p>contains functions to create single and flat multilayer networks build on networkx</p>
<p>as well as functions to estimate missing edges in order to construct complete networks</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
contains functions to create single and flat multilayer networks build on networkx

as well as functions to estimate missing edges in order to construct complete networks
&#34;&#34;&#34;

import networkx as nx
import numpy as np
import os
from multiprocessing import Pool
from functools import partial
import statistics
import dask.bag as db
import pickle
import asyncio
import sys
#sys.path.insert(1, &#39;../supporting/&#39;)
#import pickle4reducer
import multiprocessing as mp



def construct_single_layer_network(edge_list, isolated_nodes=None):
    &#34;&#34;&#34;
    builds weighted networkx graph out of edge list. 
    duplicate nodes/ edges are not added, your list can containe duplicate nodes &amp; edges (last given value will overwrite all previous ones)

    Input
        edge lists needs to be list of lists were each sublists is in format [node 1, node 2, weight, distance]
            distance value is optional
        isolated_nodes (optional): list of node ids
            if isolated_nodes is given nodes without edges are added to graph, as provided in isolated_nodes

    Output
        return networkx graph object
    
    &#34;&#34;&#34;

    G = nx.Graph()
    #added = []

    for edge in edge_list:

        # add node
        #print(&#34;edge&#34;, edge)
        G.add_node(edge[0], label=edge[0])
        # added.append(edge[0])

        G.add_node(edge[1], label=edge[1])
        # added.append(edge[1])

        # add edge
        if len(edge) &gt; 3:
            G.add_edge(edge[0], edge[1], weight=edge[2], distance=edge[3], weight_str=str(edge[2]), distance_str=str(edge[3]))
        else:

            G.add_edge(edge[0], edge[1], weight=edge[2])

    if isolated_nodes is not None:
        for node in isolated_nodes:
            G.add_node(node, label=node)

    return G



def build_complete_network(H, take_weight=None, edge_attribute=&#34;weight&#34;, method=&#34;dijkstra&#34;, in_async=True, in_multi=False, max_step = 10, max_weight=1, penalize_automatic=False, nr_chunks=10, nr_processes=10, infer=True, manual_distance=1, manual_sim=0):
    &#34;&#34;&#34;
    takes a graph and estimates weight of all missing edges based on shortest path &amp; normalizes edges

    if network contains isolated nodes they are removed

    Input
        H, networkx object: assumes weights to be distances
        
        take weight (optional) states if shortest path is based on weight of edge or not
            if none all edges are treated equal and only steps are counted 
            else take_weight needs to be str of name of edge weight

        edge_attribute
            str, name of graph edge weight attribute which is used to estimate new edge weights based on shortest paths
        
        method (optional) method how shortest path is calculated, options are
            dijkstra or &#34;bellman-ford&#34;

        

        in async (optional)
            if code is run asyncronous
        
        in_multi (optional)
            if code is run as multiprocess

            if true
                nr_chunks &amp; nr_processes set as how many tasks &amp; on how many cores code is run

        if infer
            if not penalize_automatic: if path does not exist between 2 nodes distance is set to max_step*max weight
            if penalize_automatic = True it is set max_step*longest_shortest_path_in_graph*max_weight
        else value is set after normalization to manual_distance/ manual_sim
        
    Output
        returns three networkx graphs
            graph containing distance &amp; similarity edge weights
            distance graph
            similarity graph
        
    &#34;&#34;&#34;

    G = H.copy()
    
    
    isolates = list(nx.isolates(G))
    if len(isolates) &gt; 0:
        print(&#34;Graph has isolate nodes, removing nodes &#34;, len(isolates))
        
        G.remove_nodes_from(isolates)
    
    
    #get missing edges
    non_edges = list(nx.non_edges(G))
    
    print(&#34;graph edges missing &#34;, len(non_edges))
    
    #get shortest path between these nodes to estimate new edge_weight
    

    if in_multi:
        print(&#34;running on multiple cores&#34;)
        #split non edges into chunks and run on multiple cores
        print(&#34;call get chunks&#34;)
        #chunks = list(get_chunks(non_edges,nr_chunks))
        chunks = list(np.array_split(np.array(non_edges), nr_chunks))



        print(&#34;splitting into chunks successfull start multiprocesses&#34;)

        
        
        func = partial(estimate_shortest_path, G, method=method, edge_attribute=edge_attribute, in_async=in_async, max_step = max_step, max_weight=max_weight, penalize_automatic=penalize_automatic, infer=infer)

        pool = Pool(processes=nr_processes)
    
        result = pool.map(func, chunks)

        print(&#34;missing edges estimated terminate multiprocesses&#34;)
        pool.terminate()
        pool.join()

        #combine result into new_edges
        print(&#34;merging result &#34;)
        temp_edges = []
        temp_non_path = []
        max_path = []

        for r in result:
            if len(r[&#34;edges&#34;]) &gt; 0:
                temp_edges.append(r[&#34;edges&#34;])
            if len(r[&#34;no_path&#34;]) &gt; 0:
                temp_non_path.append(r[&#34;no_path&#34;])
                max_path.append(r[&#34;longest_path&#34;])


        new_edges = [j for i in temp_edges for j in i]

        if len(temp_non_path) &gt; 0:
            no_edges_temp = [j for i in temp_non_path for j in i]
            pen_weight = max(max_path)
            print(&#34;longest shortest path is of length &#34;, pen_weight)
            if infer:
                if penalize_automatic:
                    print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight*pen_weight))
                else:
                    print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight))
                for i in no_edges_temp:
                    new_edges.append([i[0], i[1], float(max_step*max_weight*pen_weight)])

            else:
                print(&#34;non path edges are set to distance &#34;, 1)
                for i in no_edges_temp:
                    new_edges.append([i[0], i[1], 1])

    
    else:

        print(&#34;running on one core&#34;)
        result = estimate_shortest_path(G, non_edges, edge_attribute=edge_attribute, method=method, in_async=in_async, max_step = max_step, max_weight=max_weight, penalize_automatic=penalize_automatic, infer=infer)
        new_edges = result[&#34;edges&#34;]
        no_edges_temp = result[&#34;no_path&#34;]
        pen_weight = result[&#34;longest_path&#34;]
        
    
        print(&#34;longest shortest path is of length &#34;, pen_weight)
        if infer:
            if penalize_automatic:
                print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight*pen_weight))
            else:
                print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight))
            for i in no_edges_temp:
                new_edges.append([i[0], i[1], float(max_step*max_weight*pen_weight)])

        else:
            for i in no_edges_temp:
                new_edges.append([i[0], i[1], float(max_step*max_weight*pen_weight)])

    if infer:
        print(&#34;adding new edges to Graph&#34;)

        for item in new_edges:
            if len(item) &gt;= 3:
                G.add_edge(item[0], item[1])
                G[item[0]][item[1]][edge_attribute] = item[2]
            else:
                print(&#34;wrong length skip&#34;, item)


    print(&#34;normalize edges and transform into edge list&#34;)
    
    temp_edge_list = []
    
    #convert to edge list to be able to normalize &amp; calculate similarity values
    temp_edges = nx.get_edge_attributes(G, name=edge_attribute)
    
    for key in temp_edges.keys():
        
        temp_edge_list.append([key[0], key[1], temp_edges[key]])
        
        
    #normalize 
    
    distance_edges, similarity_edges, combined_edges = create_normalized_edge_list_and_similarity_list(temp_edge_list) 
        
    C =  construct_single_layer_network(combined_edges)

    D =  construct_single_layer_network(distance_edges)

    S =  construct_single_layer_network(similarity_edges)

    if not infer:
        print(&#34;adding new edges to Graphs with distance/ sim&#34;, manual_distance, manual_sim)

        for item in new_edges:
            if len(item) &gt;= 3:
                D.add_edge(item[0], item[1])
                D[item[0]][item[1]][edge_attribute] = manual_distance
                S.add_edge(item[0], item[1])
                S[item[0]][item[1]][edge_attribute] =  manual_sim
                C.add_edge(item[0], item[1],  weight=manual_sim, distance = manual_distance, weight_str=str(manual_sim), distance_str=str(manual_distance))
            else:
                print(&#34;wrong length skip&#34;, item)

    return C,D,S 


def estimate_shortest_path(G, non_edges, edge_attribute=&#34;weight&#34;, take_weight=None, method=&#34;dijkstra&#34;, max_step = 10, max_weight=1, penalize_automatic=False, in_async=True, infer=True):

    &#34;&#34;&#34;
    child function of build_complete_network
        s. build_complete_network() for parameter explanation

    estimates shortest path for all edges stored in non_edges, which is list of non existing edges in G

    Input
        refer to build_complete_network()

    Output:
        dict
    &#34;&#34;&#34;

    print(&#34;estimating shoretst path&#34;)
    try:
        non_edges = non_edges.tolist()
    except:
        non_edges=non_edges
    
    new_edges = []

    temp_edges = [] #used to save edges were no path exists to set to max

    longest_path = 1

    #run in parallel

    if in_async:
        print(&#34;start async&#34;)
        tasks =  []
        loop = asyncio.new_event_loop()

        for i in range(len(non_edges)):          
        
            
            edge=non_edges[i]

            r = tasks.append(loop.create_task(calc_estimate_shortest_path(G, edge, edge_attribute=edge_attribute, take_weight=take_weight, method=method, max_step = max_step, max_weight=max_weight, penalize_automatic=penalize_automatic, infer=infer)))

        loop.run_until_complete(asyncio.wait(tasks))

        loop.close()

        
        #merge all dicts into one 
        
        #edges occuring in multiple layers are merged into list attributes
        print(&#34;async finished merging results&#34;)
        path_lengths = []
        for r in tasks:
        
            new_edges.append(r.result()[0])
            if len(r.result()[1]) &gt; 0:
                temp_edges.append(r.result()[1])
            path_lengths.append(r.result()[2])

        longest_path = max(path_lengths)

    else:
        for i in range(len(non_edges)):
            
        
            
            edge=non_edges[i]
            
            #print(edge)
            
            if nx.has_path(G, edge[0], edge[1]):
                #if shortest path cannot be found weight is set to max_step * max_weight
                shortest_path = nx.shortest_path(G, source=edge[0], target=edge[1], weight=take_weight, method=method)

                #estimate new edge weight by adding up weights of paths
                #returns list of nodes
                previous_node = None
                target_node = edge[1]
                start_node = edge[0]

                if len(shortest_path) &gt; longest_path:
                    longest_path = len(shortest_path)

                value = 0

                #print(&#34;shortest_path &#34;, shortest_path)


                for i in range(len(shortest_path)):

                    current_node = shortest_path[i]

                    if current_node == start_node:
                        previous_node = current_node

                    if current_node == target_node:
                        #reached end

                        weight = G[previous_node][current_node][edge_attribute]
                        #print(&#34;last weight&#34;, weight)
                        #update new weight
                        value = value + weight

                        #print(&#34;edge completed &#34;, value)
                        new_edges.append([start_node, target_node, value])

                    else:
                        #estimate path value
                        if previous_node != current_node:
                            #get edge weight
                            weight = G[previous_node][current_node][edge_attribute]
                            #print(&#34;weight&#34;, weight)
                            #update new weight
                            value = value + weight

                            previous_node=current_node
                        #else:
                        #    print(&#34;start node start calculation&#34;)

            else:
                #print(&#34;no path between nodes weight is set to max &#34;, edge[0], edge[1], float(max_step*max_weight))
                if infer:
                    if not penalize_automatic:
                        new_edges.append([edge[0], edge[1], float(max_step*max_weight)])
                    else:
                        temp_edges.append([edge[0], edge[1]])

                else:
                    temp_edges.append([edge[0], edge[1]])

    
        



    return {&#34;edges&#34;: new_edges, &#34;no_path&#34;: temp_edges, &#34;longest_path&#34;:longest_path}

async def calc_estimate_shortest_path(G, edge, edge_attribute=&#34;weight&#34;, take_weight=None, method=&#34;dijkstra&#34;, max_step = 10, max_weight=1, penalize_automatic=False, infer=True):

    &#34;&#34;&#34;
    async version to estimate shortest path between two nodes
    helper function of build_complete_network() &amp; estimate_shortest_path()

    Input
        refer to build_complete_network() &amp; estimate_shortest_path()

    Output
        returns tuple of new edges 
    &#34;&#34;&#34;


    new_edge = []
    temp_edge = []
    path_length = 0


    if nx.has_path(G, edge[0], edge[1]):
            #if shortest path cannot be found weight is set to max_step * max_weight
            shortest_path = nx.shortest_path(G, source=edge[0], target=edge[1], weight=take_weight, method=method)

            #estimate new edge weight by adding up weights of paths
            #returns list of nodes
            previous_node = None
            target_node = edge[1]
            start_node = edge[0]

            path_length = len(shortest_path) 

            value = 0

            #print(&#34;shortest_path &#34;, shortest_path)


            for i in range(len(shortest_path)):

                current_node = shortest_path[i]

                if current_node == start_node:
                    previous_node = current_node

                if current_node == target_node:
                    #reached end

                    weight = G[previous_node][current_node][edge_attribute]
                    #print(&#34;last weight&#34;, weight)
                    #update new weight
                    value = value + weight

                    #print(&#34;edge completed &#34;, value)
                    new_edge = [start_node, target_node, value]

                else:
                    #estimate path value
                    if previous_node != current_node:
                        #get edge weight
                        weight = G[previous_node][current_node][edge_attribute]
                        #print(&#34;weight&#34;, weight)
                        #update new weight
                        value = value + weight

                        previous_node=current_node
                    #else:
                    #    print(&#34;start node start calculation&#34;)

    else:
        #print(&#34;no path between nodes weight is set to max &#34;, edge[0], edge[1], float(max_step*max_weight))
        if infer:
            if not penalize_automatic:
                new_edge = [edge[0], edge[1], float(max_step*max_weight)]
            else:
                temp_edge = [edge[0], edge[1]]

        else:
            temp_edge = [edge[0], edge[1]]


    return (new_edge, temp_edge, path_length)


def create_normalized_edge_list_and_similarity_list(edge_list, normalized=True, distance=True, combined=True):
    &#34;&#34;&#34;
    helper function of build_complete_network() to normalize edge scores
    
    assumes scores in edge list are distance values (if similarity values take into account that returned distance and similarity results are switched)

    Input
        edge list as list of sublists where each sublist is in format [node1, node2, weight]

    Output
        returns 3 lists of sublists
            normalized distance edge list
            normalized similarity edge list
            combined edge list
        in format as edge_list where each sublists is [node 1, node 2, distance] or [node 1, node 2, similarity] or [node 1, node 2, distance, similarity]

    
    &#34;&#34;&#34;
    # print(edge_list)

    gene1 = [item[0] for item in edge_list]
    gene2 = [item[1] for item in edge_list]
    score = [item[2] for item in edge_list]

    # normalize to be between 0 &amp; 1

    print(&#34;normalizing score of length &#34;, len(score))

    normalized = normalize(score)

    print(&#34;update edges &#34;, len(gene1))

    normalized_edge_list = []
    similarity_edge_list = []
    combined_edge_list = []

    for k in range(len(gene1)):
        if k % 10000 == 0:
            print(&#34;normalizing &#34; + str(k))

        similarity = 1 - float(normalized[k])
        if normalized:
            normalized_edge_list.append([gene1[k], gene2[k], normalized[k]])
        else:
            normalized_edge_list = None
        if distance:
            similarity_edge_list.append([gene1[k], gene2[k], similarity])
        else:
            similarity_edge_list = None
        if combined:
            combined_edge_list.append(
                [gene1[k], gene2[k], normalized[k], similarity])
        else:
            combined_edge_list = None

    return normalized_edge_list, similarity_edge_list, combined_edge_list


def normalize(a, offset=0.0001):
    &#34;&#34;&#34;
    normalization function

    Input
        a is list of floats

        offset offset to be added to values to avoid 1 &amp; 0 values after normalization

    Output
        list of floats in same order as a

    
    &#34;&#34;&#34;

    # add small offset to not fully reach value 1
    min_val = min(a) - offset

    max_val = max(a) + offset

    norm = [(val-min_val) / (max_val-min_val) for val in a]

    return norm


def construct_multilayer_network_matrix(layers, weights):
    &#34;&#34;&#34;
    function to create a flat multilayer network, while propagating each layers edge weight
        merges layers based on adjacency matrices
        matrices need to have same dimensions for all layers and need to be ordered the same way

    Input
        layers
            list of adjacency matrices, one for each layer
            numpy matrices

            use reformat_G_to_adj_matrix to convert graph object into adjacency matrix
        weights
            list of float
            weights are used to scale layers, need to be in same order as layers

            weights can be set manually or estimated based on functions provided in scaling.py
                this allows to individually weight and estimate the &#34;importance&#34;/ &#34;quality&#34; of individual layers

    
    Output
        two adjacency matrices, with normalized and unnormalized edge weights
    &#34;&#34;&#34;

    if len(layers) != len(weights):
        print(&#34;layers and weights have different dimensions&#34;)
        return None, None
    else:
        # multiply matrices with scaling factor
        unnormalized = np.zeros((layers[0].shape))
        for i in range(len(layers)):
            unnormalized = unnormalized + weights[i] * layers[i]

        print(&#34;creating normalized&#34;)
        normalized = (unnormalized - np.min(unnormalized)) / \
            (((np.max(unnormalized)+0.0001)-np.min(unnormalized)))

        return unnormalized, normalized


def reformat_G_to_adj_matrix(G, gene_list=None):
    &#34;&#34;&#34;
    converts a graph object into an adjacency matrix
    based on networkx 

    Input
        G
            networkx graph object

        gene_list (optional)
            in order to keep all layers consistent provide gene_list, which is list of node ids for all layers
                need to be same list for all layers!! even if it contains missing nodes

            if None then ouput of G.nodes() will be used
    Output
        numpy matrix
    
    &#34;&#34;&#34;

    # add missing genes
    if gene_list is not None:
        for gene in gene_list:
            if gene not in list(G.nodes()):
                G.add_node(gene)

    # get adjacency matrix

    adj_matrix = nx.to_numpy_matrix(G, nodelist=gene_list)

    return adj_matrix


def reformat_edge_list(edge_list):
    &#34;&#34;&#34;
    helper function to separate edges from their corresponding weight values

    Input
        edge_list
            list of sublists [n1, n2, weight]

    Output
        two lists containing edges and scores in same order as edge_list
    
    &#34;&#34;&#34;

    # reformats edge lists into two lists containing edges and corresponding scores

    if edge_list is not None:
        edge_list_edge = [[edge[0], edge[1]] for edge in edge_list]
        edge_list_score = [edge[2] for edge in edge_list]

    else:
        edge_list_edge = None
        edge_list_score = None

    return edge_list_edge, edge_list_score


def relable_nodes(H):
    &#34;&#34;&#34;
    function needed when converting networkx object to igraph 
    igraph does not allow to have &#34;gaps in node ids&#34;,
    therefore ids are relabled after isolated nodes are removed to have consistent labeling

    Input
        networkx graph object

    Output
        function returns two dicts and the relabled graph object where isolated nodes have been removed
            the first one containing the mapping to create the new graph, the second one that can be used to revers the labeling

    &#34;&#34;&#34;

    G = H.copy()
    # remove isolates
    G.remove_nodes_from(list(nx.isolates(G)))

    new_ids = {}
    reverse = {}
    # get all nodes and relable
    nodes = list(G.nodes())
    count = 0
    for node in nodes:
        new_ids[node] = count
        reverse[count] = node

        count = count + 1

    # update graph
    G = nx.relabel_nodes(G, new_ids, copy=False)

    # to reverse run nx.relabel_nodes(G, reverse, copy=False)
    return new_ids, reverse, G


def reverse_relable_nodes(H, mapping):
    &#34;&#34;&#34;
    function to reverse relabeling of nodes as performed by relable_nodes

    Input
        networkx graph object
        reverse mapping as returned by relable_nodes as second item

    Output
        relabled graph object (isolated nodes are still removed but node names are consistent with original graph)
    &#34;&#34;&#34;

    G = H.copy()

    G = nx.relabel_nodes(G, mapping, copy=False)

    return G</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="graphAlgorithms.multiplex.build_network.build_complete_network"><code class="name flex">
<span>def <span class="ident">build_complete_network</span></span>(<span>H, take_weight=None, edge_attribute='weight', method='dijkstra', in_async=True, in_multi=False, max_step=10, max_weight=1, penalize_automatic=False, nr_chunks=10, nr_processes=10, infer=True, manual_distance=1, manual_sim=0)</span>
</code></dt>
<dd>
<section class="desc"><p>takes a graph and estimates weight of all missing edges based on shortest path &amp; normalizes edges</p>
<p>if network contains isolated nodes they are removed</p>
<p>Input
H, networkx object: assumes weights to be distances</p>
<pre><code>take weight (optional) states if shortest path is based on weight of edge or not
    if none all edges are treated equal and only steps are counted 
    else take_weight needs to be str of name of edge weight

edge_attribute
    str, name of graph edge weight attribute which is used to estimate new edge weights based on shortest paths

method (optional) method how shortest path is calculated, options are
    dijkstra or "bellman-ford"



in async (optional)
    if code is run asyncronous

in_multi (optional)
    if code is run as multiprocess

    if true
        nr_chunks &amp; nr_processes set as how many tasks &amp; on how many cores code is run

if infer
    if not penalize_automatic: if path does not exist between 2 nodes distance is set to max_step*max weight
    if penalize_automatic = True it is set max_step*longest_shortest_path_in_graph*max_weight
else value is set after normalization to manual_distance/ manual_sim
</code></pre>
<p>Output
returns three networkx graphs
graph containing distance &amp; similarity edge weights
distance graph
similarity graph</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_complete_network(H, take_weight=None, edge_attribute=&#34;weight&#34;, method=&#34;dijkstra&#34;, in_async=True, in_multi=False, max_step = 10, max_weight=1, penalize_automatic=False, nr_chunks=10, nr_processes=10, infer=True, manual_distance=1, manual_sim=0):
    &#34;&#34;&#34;
    takes a graph and estimates weight of all missing edges based on shortest path &amp; normalizes edges

    if network contains isolated nodes they are removed

    Input
        H, networkx object: assumes weights to be distances
        
        take weight (optional) states if shortest path is based on weight of edge or not
            if none all edges are treated equal and only steps are counted 
            else take_weight needs to be str of name of edge weight

        edge_attribute
            str, name of graph edge weight attribute which is used to estimate new edge weights based on shortest paths
        
        method (optional) method how shortest path is calculated, options are
            dijkstra or &#34;bellman-ford&#34;

        

        in async (optional)
            if code is run asyncronous
        
        in_multi (optional)
            if code is run as multiprocess

            if true
                nr_chunks &amp; nr_processes set as how many tasks &amp; on how many cores code is run

        if infer
            if not penalize_automatic: if path does not exist between 2 nodes distance is set to max_step*max weight
            if penalize_automatic = True it is set max_step*longest_shortest_path_in_graph*max_weight
        else value is set after normalization to manual_distance/ manual_sim
        
    Output
        returns three networkx graphs
            graph containing distance &amp; similarity edge weights
            distance graph
            similarity graph
        
    &#34;&#34;&#34;

    G = H.copy()
    
    
    isolates = list(nx.isolates(G))
    if len(isolates) &gt; 0:
        print(&#34;Graph has isolate nodes, removing nodes &#34;, len(isolates))
        
        G.remove_nodes_from(isolates)
    
    
    #get missing edges
    non_edges = list(nx.non_edges(G))
    
    print(&#34;graph edges missing &#34;, len(non_edges))
    
    #get shortest path between these nodes to estimate new edge_weight
    

    if in_multi:
        print(&#34;running on multiple cores&#34;)
        #split non edges into chunks and run on multiple cores
        print(&#34;call get chunks&#34;)
        #chunks = list(get_chunks(non_edges,nr_chunks))
        chunks = list(np.array_split(np.array(non_edges), nr_chunks))



        print(&#34;splitting into chunks successfull start multiprocesses&#34;)

        
        
        func = partial(estimate_shortest_path, G, method=method, edge_attribute=edge_attribute, in_async=in_async, max_step = max_step, max_weight=max_weight, penalize_automatic=penalize_automatic, infer=infer)

        pool = Pool(processes=nr_processes)
    
        result = pool.map(func, chunks)

        print(&#34;missing edges estimated terminate multiprocesses&#34;)
        pool.terminate()
        pool.join()

        #combine result into new_edges
        print(&#34;merging result &#34;)
        temp_edges = []
        temp_non_path = []
        max_path = []

        for r in result:
            if len(r[&#34;edges&#34;]) &gt; 0:
                temp_edges.append(r[&#34;edges&#34;])
            if len(r[&#34;no_path&#34;]) &gt; 0:
                temp_non_path.append(r[&#34;no_path&#34;])
                max_path.append(r[&#34;longest_path&#34;])


        new_edges = [j for i in temp_edges for j in i]

        if len(temp_non_path) &gt; 0:
            no_edges_temp = [j for i in temp_non_path for j in i]
            pen_weight = max(max_path)
            print(&#34;longest shortest path is of length &#34;, pen_weight)
            if infer:
                if penalize_automatic:
                    print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight*pen_weight))
                else:
                    print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight))
                for i in no_edges_temp:
                    new_edges.append([i[0], i[1], float(max_step*max_weight*pen_weight)])

            else:
                print(&#34;non path edges are set to distance &#34;, 1)
                for i in no_edges_temp:
                    new_edges.append([i[0], i[1], 1])

    
    else:

        print(&#34;running on one core&#34;)
        result = estimate_shortest_path(G, non_edges, edge_attribute=edge_attribute, method=method, in_async=in_async, max_step = max_step, max_weight=max_weight, penalize_automatic=penalize_automatic, infer=infer)
        new_edges = result[&#34;edges&#34;]
        no_edges_temp = result[&#34;no_path&#34;]
        pen_weight = result[&#34;longest_path&#34;]
        
    
        print(&#34;longest shortest path is of length &#34;, pen_weight)
        if infer:
            if penalize_automatic:
                print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight*pen_weight))
            else:
                print(&#34;non path edges are set to distance &#34;, float(max_step*max_weight))
            for i in no_edges_temp:
                new_edges.append([i[0], i[1], float(max_step*max_weight*pen_weight)])

        else:
            for i in no_edges_temp:
                new_edges.append([i[0], i[1], float(max_step*max_weight*pen_weight)])

    if infer:
        print(&#34;adding new edges to Graph&#34;)

        for item in new_edges:
            if len(item) &gt;= 3:
                G.add_edge(item[0], item[1])
                G[item[0]][item[1]][edge_attribute] = item[2]
            else:
                print(&#34;wrong length skip&#34;, item)


    print(&#34;normalize edges and transform into edge list&#34;)
    
    temp_edge_list = []
    
    #convert to edge list to be able to normalize &amp; calculate similarity values
    temp_edges = nx.get_edge_attributes(G, name=edge_attribute)
    
    for key in temp_edges.keys():
        
        temp_edge_list.append([key[0], key[1], temp_edges[key]])
        
        
    #normalize 
    
    distance_edges, similarity_edges, combined_edges = create_normalized_edge_list_and_similarity_list(temp_edge_list) 
        
    C =  construct_single_layer_network(combined_edges)

    D =  construct_single_layer_network(distance_edges)

    S =  construct_single_layer_network(similarity_edges)

    if not infer:
        print(&#34;adding new edges to Graphs with distance/ sim&#34;, manual_distance, manual_sim)

        for item in new_edges:
            if len(item) &gt;= 3:
                D.add_edge(item[0], item[1])
                D[item[0]][item[1]][edge_attribute] = manual_distance
                S.add_edge(item[0], item[1])
                S[item[0]][item[1]][edge_attribute] =  manual_sim
                C.add_edge(item[0], item[1],  weight=manual_sim, distance = manual_distance, weight_str=str(manual_sim), distance_str=str(manual_distance))
            else:
                print(&#34;wrong length skip&#34;, item)

    return C,D,S </code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.calc_estimate_shortest_path"><code class="name flex">
<span>async def <span class="ident">calc_estimate_shortest_path</span></span>(<span>G, edge, edge_attribute='weight', take_weight=None, method='dijkstra', max_step=10, max_weight=1, penalize_automatic=False, infer=True)</span>
</code></dt>
<dd>
<section class="desc"><p>async version to estimate shortest path between two nodes
helper function of build_complete_network() &amp; estimate_shortest_path()</p>
<p>Input
refer to build_complete_network() &amp; estimate_shortest_path()</p>
<p>Output
returns tuple of new edges</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def calc_estimate_shortest_path(G, edge, edge_attribute=&#34;weight&#34;, take_weight=None, method=&#34;dijkstra&#34;, max_step = 10, max_weight=1, penalize_automatic=False, infer=True):

    &#34;&#34;&#34;
    async version to estimate shortest path between two nodes
    helper function of build_complete_network() &amp; estimate_shortest_path()

    Input
        refer to build_complete_network() &amp; estimate_shortest_path()

    Output
        returns tuple of new edges 
    &#34;&#34;&#34;


    new_edge = []
    temp_edge = []
    path_length = 0


    if nx.has_path(G, edge[0], edge[1]):
            #if shortest path cannot be found weight is set to max_step * max_weight
            shortest_path = nx.shortest_path(G, source=edge[0], target=edge[1], weight=take_weight, method=method)

            #estimate new edge weight by adding up weights of paths
            #returns list of nodes
            previous_node = None
            target_node = edge[1]
            start_node = edge[0]

            path_length = len(shortest_path) 

            value = 0

            #print(&#34;shortest_path &#34;, shortest_path)


            for i in range(len(shortest_path)):

                current_node = shortest_path[i]

                if current_node == start_node:
                    previous_node = current_node

                if current_node == target_node:
                    #reached end

                    weight = G[previous_node][current_node][edge_attribute]
                    #print(&#34;last weight&#34;, weight)
                    #update new weight
                    value = value + weight

                    #print(&#34;edge completed &#34;, value)
                    new_edge = [start_node, target_node, value]

                else:
                    #estimate path value
                    if previous_node != current_node:
                        #get edge weight
                        weight = G[previous_node][current_node][edge_attribute]
                        #print(&#34;weight&#34;, weight)
                        #update new weight
                        value = value + weight

                        previous_node=current_node
                    #else:
                    #    print(&#34;start node start calculation&#34;)

    else:
        #print(&#34;no path between nodes weight is set to max &#34;, edge[0], edge[1], float(max_step*max_weight))
        if infer:
            if not penalize_automatic:
                new_edge = [edge[0], edge[1], float(max_step*max_weight)]
            else:
                temp_edge = [edge[0], edge[1]]

        else:
            temp_edge = [edge[0], edge[1]]


    return (new_edge, temp_edge, path_length)</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.construct_multilayer_network_matrix"><code class="name flex">
<span>def <span class="ident">construct_multilayer_network_matrix</span></span>(<span>layers, weights)</span>
</code></dt>
<dd>
<section class="desc"><p>function to create a flat multilayer network, while propagating each layers edge weight
merges layers based on adjacency matrices
matrices need to have same dimensions for all layers and need to be ordered the same way</p>
<p>Input
layers
list of adjacency matrices, one for each layer
numpy matrices</p>
<pre><code>    use reformat_G_to_adj_matrix to convert graph object into adjacency matrix
weights
    list of float
    weights are used to scale layers, need to be in same order as layers

    weights can be set manually or estimated based on functions provided in scaling.py
        this allows to individually weight and estimate the "importance"/ "quality" of individual layers
</code></pre>
<p>Output
two adjacency matrices, with normalized and unnormalized edge weights</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_multilayer_network_matrix(layers, weights):
    &#34;&#34;&#34;
    function to create a flat multilayer network, while propagating each layers edge weight
        merges layers based on adjacency matrices
        matrices need to have same dimensions for all layers and need to be ordered the same way

    Input
        layers
            list of adjacency matrices, one for each layer
            numpy matrices

            use reformat_G_to_adj_matrix to convert graph object into adjacency matrix
        weights
            list of float
            weights are used to scale layers, need to be in same order as layers

            weights can be set manually or estimated based on functions provided in scaling.py
                this allows to individually weight and estimate the &#34;importance&#34;/ &#34;quality&#34; of individual layers

    
    Output
        two adjacency matrices, with normalized and unnormalized edge weights
    &#34;&#34;&#34;

    if len(layers) != len(weights):
        print(&#34;layers and weights have different dimensions&#34;)
        return None, None
    else:
        # multiply matrices with scaling factor
        unnormalized = np.zeros((layers[0].shape))
        for i in range(len(layers)):
            unnormalized = unnormalized + weights[i] * layers[i]

        print(&#34;creating normalized&#34;)
        normalized = (unnormalized - np.min(unnormalized)) / \
            (((np.max(unnormalized)+0.0001)-np.min(unnormalized)))

        return unnormalized, normalized</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.construct_single_layer_network"><code class="name flex">
<span>def <span class="ident">construct_single_layer_network</span></span>(<span>edge_list, isolated_nodes=None)</span>
</code></dt>
<dd>
<section class="desc"><p>builds weighted networkx graph out of edge list.
duplicate nodes/ edges are not added, your list can containe duplicate nodes &amp; edges (last given value will overwrite all previous ones)</p>
<p>Input
edge lists needs to be list of lists were each sublists is in format [node 1, node 2, weight, distance]
distance value is optional
isolated_nodes (optional): list of node ids
if isolated_nodes is given nodes without edges are added to graph, as provided in isolated_nodes</p>
<p>Output
return networkx graph object</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_single_layer_network(edge_list, isolated_nodes=None):
    &#34;&#34;&#34;
    builds weighted networkx graph out of edge list. 
    duplicate nodes/ edges are not added, your list can containe duplicate nodes &amp; edges (last given value will overwrite all previous ones)

    Input
        edge lists needs to be list of lists were each sublists is in format [node 1, node 2, weight, distance]
            distance value is optional
        isolated_nodes (optional): list of node ids
            if isolated_nodes is given nodes without edges are added to graph, as provided in isolated_nodes

    Output
        return networkx graph object
    
    &#34;&#34;&#34;

    G = nx.Graph()
    #added = []

    for edge in edge_list:

        # add node
        #print(&#34;edge&#34;, edge)
        G.add_node(edge[0], label=edge[0])
        # added.append(edge[0])

        G.add_node(edge[1], label=edge[1])
        # added.append(edge[1])

        # add edge
        if len(edge) &gt; 3:
            G.add_edge(edge[0], edge[1], weight=edge[2], distance=edge[3], weight_str=str(edge[2]), distance_str=str(edge[3]))
        else:

            G.add_edge(edge[0], edge[1], weight=edge[2])

    if isolated_nodes is not None:
        for node in isolated_nodes:
            G.add_node(node, label=node)

    return G</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.create_normalized_edge_list_and_similarity_list"><code class="name flex">
<span>def <span class="ident">create_normalized_edge_list_and_similarity_list</span></span>(<span>edge_list, normalized=True, distance=True, combined=True)</span>
</code></dt>
<dd>
<section class="desc"><p>helper function of build_complete_network() to normalize edge scores</p>
<p>assumes scores in edge list are distance values (if similarity values take into account that returned distance and similarity results are switched)</p>
<p>Input
edge list as list of sublists where each sublist is in format [node1, node2, weight]</p>
<p>Output
returns 3 lists of sublists
normalized distance edge list
normalized similarity edge list
combined edge list
in format as edge_list where each sublists is [node 1, node 2, distance] or [node 1, node 2, similarity] or [node 1, node 2, distance, similarity]</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_normalized_edge_list_and_similarity_list(edge_list, normalized=True, distance=True, combined=True):
    &#34;&#34;&#34;
    helper function of build_complete_network() to normalize edge scores
    
    assumes scores in edge list are distance values (if similarity values take into account that returned distance and similarity results are switched)

    Input
        edge list as list of sublists where each sublist is in format [node1, node2, weight]

    Output
        returns 3 lists of sublists
            normalized distance edge list
            normalized similarity edge list
            combined edge list
        in format as edge_list where each sublists is [node 1, node 2, distance] or [node 1, node 2, similarity] or [node 1, node 2, distance, similarity]

    
    &#34;&#34;&#34;
    # print(edge_list)

    gene1 = [item[0] for item in edge_list]
    gene2 = [item[1] for item in edge_list]
    score = [item[2] for item in edge_list]

    # normalize to be between 0 &amp; 1

    print(&#34;normalizing score of length &#34;, len(score))

    normalized = normalize(score)

    print(&#34;update edges &#34;, len(gene1))

    normalized_edge_list = []
    similarity_edge_list = []
    combined_edge_list = []

    for k in range(len(gene1)):
        if k % 10000 == 0:
            print(&#34;normalizing &#34; + str(k))

        similarity = 1 - float(normalized[k])
        if normalized:
            normalized_edge_list.append([gene1[k], gene2[k], normalized[k]])
        else:
            normalized_edge_list = None
        if distance:
            similarity_edge_list.append([gene1[k], gene2[k], similarity])
        else:
            similarity_edge_list = None
        if combined:
            combined_edge_list.append(
                [gene1[k], gene2[k], normalized[k], similarity])
        else:
            combined_edge_list = None

    return normalized_edge_list, similarity_edge_list, combined_edge_list</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.estimate_shortest_path"><code class="name flex">
<span>def <span class="ident">estimate_shortest_path</span></span>(<span>G, non_edges, edge_attribute='weight', take_weight=None, method='dijkstra', max_step=10, max_weight=1, penalize_automatic=False, in_async=True, infer=True)</span>
</code></dt>
<dd>
<section class="desc"><p>child function of build_complete_network
s. build_complete_network() for parameter explanation</p>
<p>estimates shortest path for all edges stored in non_edges, which is list of non existing edges in G</p>
<p>Input
refer to build_complete_network()</p>
<h2 id="output">Output</h2>
<dl>
<dt><strong><code>dict</code></strong></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_shortest_path(G, non_edges, edge_attribute=&#34;weight&#34;, take_weight=None, method=&#34;dijkstra&#34;, max_step = 10, max_weight=1, penalize_automatic=False, in_async=True, infer=True):

    &#34;&#34;&#34;
    child function of build_complete_network
        s. build_complete_network() for parameter explanation

    estimates shortest path for all edges stored in non_edges, which is list of non existing edges in G

    Input
        refer to build_complete_network()

    Output:
        dict
    &#34;&#34;&#34;

    print(&#34;estimating shoretst path&#34;)
    try:
        non_edges = non_edges.tolist()
    except:
        non_edges=non_edges
    
    new_edges = []

    temp_edges = [] #used to save edges were no path exists to set to max

    longest_path = 1

    #run in parallel

    if in_async:
        print(&#34;start async&#34;)
        tasks =  []
        loop = asyncio.new_event_loop()

        for i in range(len(non_edges)):          
        
            
            edge=non_edges[i]

            r = tasks.append(loop.create_task(calc_estimate_shortest_path(G, edge, edge_attribute=edge_attribute, take_weight=take_weight, method=method, max_step = max_step, max_weight=max_weight, penalize_automatic=penalize_automatic, infer=infer)))

        loop.run_until_complete(asyncio.wait(tasks))

        loop.close()

        
        #merge all dicts into one 
        
        #edges occuring in multiple layers are merged into list attributes
        print(&#34;async finished merging results&#34;)
        path_lengths = []
        for r in tasks:
        
            new_edges.append(r.result()[0])
            if len(r.result()[1]) &gt; 0:
                temp_edges.append(r.result()[1])
            path_lengths.append(r.result()[2])

        longest_path = max(path_lengths)

    else:
        for i in range(len(non_edges)):
            
        
            
            edge=non_edges[i]
            
            #print(edge)
            
            if nx.has_path(G, edge[0], edge[1]):
                #if shortest path cannot be found weight is set to max_step * max_weight
                shortest_path = nx.shortest_path(G, source=edge[0], target=edge[1], weight=take_weight, method=method)

                #estimate new edge weight by adding up weights of paths
                #returns list of nodes
                previous_node = None
                target_node = edge[1]
                start_node = edge[0]

                if len(shortest_path) &gt; longest_path:
                    longest_path = len(shortest_path)

                value = 0

                #print(&#34;shortest_path &#34;, shortest_path)


                for i in range(len(shortest_path)):

                    current_node = shortest_path[i]

                    if current_node == start_node:
                        previous_node = current_node

                    if current_node == target_node:
                        #reached end

                        weight = G[previous_node][current_node][edge_attribute]
                        #print(&#34;last weight&#34;, weight)
                        #update new weight
                        value = value + weight

                        #print(&#34;edge completed &#34;, value)
                        new_edges.append([start_node, target_node, value])

                    else:
                        #estimate path value
                        if previous_node != current_node:
                            #get edge weight
                            weight = G[previous_node][current_node][edge_attribute]
                            #print(&#34;weight&#34;, weight)
                            #update new weight
                            value = value + weight

                            previous_node=current_node
                        #else:
                        #    print(&#34;start node start calculation&#34;)

            else:
                #print(&#34;no path between nodes weight is set to max &#34;, edge[0], edge[1], float(max_step*max_weight))
                if infer:
                    if not penalize_automatic:
                        new_edges.append([edge[0], edge[1], float(max_step*max_weight)])
                    else:
                        temp_edges.append([edge[0], edge[1]])

                else:
                    temp_edges.append([edge[0], edge[1]])

    
        



    return {&#34;edges&#34;: new_edges, &#34;no_path&#34;: temp_edges, &#34;longest_path&#34;:longest_path}</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>a, offset=0.0001)</span>
</code></dt>
<dd>
<section class="desc"><p>normalization function</p>
<p>Input
a is list of floats</p>
<pre><code>offset offset to be added to values to avoid 1 &amp; 0 values after normalization
</code></pre>
<p>Output
list of floats in same order as a</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize(a, offset=0.0001):
    &#34;&#34;&#34;
    normalization function

    Input
        a is list of floats

        offset offset to be added to values to avoid 1 &amp; 0 values after normalization

    Output
        list of floats in same order as a

    
    &#34;&#34;&#34;

    # add small offset to not fully reach value 1
    min_val = min(a) - offset

    max_val = max(a) + offset

    norm = [(val-min_val) / (max_val-min_val) for val in a]

    return norm</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.reformat_G_to_adj_matrix"><code class="name flex">
<span>def <span class="ident">reformat_G_to_adj_matrix</span></span>(<span>G, gene_list=None)</span>
</code></dt>
<dd>
<section class="desc"><p>converts a graph object into an adjacency matrix
based on networkx </p>
<p>Input
G
networkx graph object</p>
<pre><code>gene_list (optional)
    in order to keep all layers consistent provide gene_list, which is list of node ids for all layers
        need to be same list for all layers!! even if it contains missing nodes

    if None then ouput of G.nodes() will be used
</code></pre>
<p>Output
numpy matrix</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reformat_G_to_adj_matrix(G, gene_list=None):
    &#34;&#34;&#34;
    converts a graph object into an adjacency matrix
    based on networkx 

    Input
        G
            networkx graph object

        gene_list (optional)
            in order to keep all layers consistent provide gene_list, which is list of node ids for all layers
                need to be same list for all layers!! even if it contains missing nodes

            if None then ouput of G.nodes() will be used
    Output
        numpy matrix
    
    &#34;&#34;&#34;

    # add missing genes
    if gene_list is not None:
        for gene in gene_list:
            if gene not in list(G.nodes()):
                G.add_node(gene)

    # get adjacency matrix

    adj_matrix = nx.to_numpy_matrix(G, nodelist=gene_list)

    return adj_matrix</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.reformat_edge_list"><code class="name flex">
<span>def <span class="ident">reformat_edge_list</span></span>(<span>edge_list)</span>
</code></dt>
<dd>
<section class="desc"><p>helper function to separate edges from their corresponding weight values</p>
<p>Input
edge_list
list of sublists [n1, n2, weight]</p>
<p>Output
two lists containing edges and scores in same order as edge_list</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reformat_edge_list(edge_list):
    &#34;&#34;&#34;
    helper function to separate edges from their corresponding weight values

    Input
        edge_list
            list of sublists [n1, n2, weight]

    Output
        two lists containing edges and scores in same order as edge_list
    
    &#34;&#34;&#34;

    # reformats edge lists into two lists containing edges and corresponding scores

    if edge_list is not None:
        edge_list_edge = [[edge[0], edge[1]] for edge in edge_list]
        edge_list_score = [edge[2] for edge in edge_list]

    else:
        edge_list_edge = None
        edge_list_score = None

    return edge_list_edge, edge_list_score</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.relable_nodes"><code class="name flex">
<span>def <span class="ident">relable_nodes</span></span>(<span>H)</span>
</code></dt>
<dd>
<section class="desc"><p>function needed when converting networkx object to igraph
igraph does not allow to have "gaps in node ids",
therefore ids are relabled after isolated nodes are removed to have consistent labeling</p>
<p>Input
networkx graph object</p>
<p>Output
function returns two dicts and the relabled graph object where isolated nodes have been removed
the first one containing the mapping to create the new graph, the second one that can be used to revers the labeling</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def relable_nodes(H):
    &#34;&#34;&#34;
    function needed when converting networkx object to igraph 
    igraph does not allow to have &#34;gaps in node ids&#34;,
    therefore ids are relabled after isolated nodes are removed to have consistent labeling

    Input
        networkx graph object

    Output
        function returns two dicts and the relabled graph object where isolated nodes have been removed
            the first one containing the mapping to create the new graph, the second one that can be used to revers the labeling

    &#34;&#34;&#34;

    G = H.copy()
    # remove isolates
    G.remove_nodes_from(list(nx.isolates(G)))

    new_ids = {}
    reverse = {}
    # get all nodes and relable
    nodes = list(G.nodes())
    count = 0
    for node in nodes:
        new_ids[node] = count
        reverse[count] = node

        count = count + 1

    # update graph
    G = nx.relabel_nodes(G, new_ids, copy=False)

    # to reverse run nx.relabel_nodes(G, reverse, copy=False)
    return new_ids, reverse, G</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.multiplex.build_network.reverse_relable_nodes"><code class="name flex">
<span>def <span class="ident">reverse_relable_nodes</span></span>(<span>H, mapping)</span>
</code></dt>
<dd>
<section class="desc"><p>function to reverse relabeling of nodes as performed by relable_nodes</p>
<p>Input
networkx graph object
reverse mapping as returned by relable_nodes as second item</p>
<p>Output
relabled graph object (isolated nodes are still removed but node names are consistent with original graph)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reverse_relable_nodes(H, mapping):
    &#34;&#34;&#34;
    function to reverse relabeling of nodes as performed by relable_nodes

    Input
        networkx graph object
        reverse mapping as returned by relable_nodes as second item

    Output
        relabled graph object (isolated nodes are still removed but node names are consistent with original graph)
    &#34;&#34;&#34;

    G = H.copy()

    G = nx.relabel_nodes(G, mapping, copy=False)

    return G</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="graphAlgorithms.multiplex" href="index.html">graphAlgorithms.multiplex</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="graphAlgorithms.multiplex.build_network.build_complete_network" href="#graphAlgorithms.multiplex.build_network.build_complete_network">build_complete_network</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.calc_estimate_shortest_path" href="#graphAlgorithms.multiplex.build_network.calc_estimate_shortest_path">calc_estimate_shortest_path</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.construct_multilayer_network_matrix" href="#graphAlgorithms.multiplex.build_network.construct_multilayer_network_matrix">construct_multilayer_network_matrix</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.construct_single_layer_network" href="#graphAlgorithms.multiplex.build_network.construct_single_layer_network">construct_single_layer_network</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.create_normalized_edge_list_and_similarity_list" href="#graphAlgorithms.multiplex.build_network.create_normalized_edge_list_and_similarity_list">create_normalized_edge_list_and_similarity_list</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.estimate_shortest_path" href="#graphAlgorithms.multiplex.build_network.estimate_shortest_path">estimate_shortest_path</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.normalize" href="#graphAlgorithms.multiplex.build_network.normalize">normalize</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.reformat_G_to_adj_matrix" href="#graphAlgorithms.multiplex.build_network.reformat_G_to_adj_matrix">reformat_G_to_adj_matrix</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.reformat_edge_list" href="#graphAlgorithms.multiplex.build_network.reformat_edge_list">reformat_edge_list</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.relable_nodes" href="#graphAlgorithms.multiplex.build_network.relable_nodes">relable_nodes</a></code></li>
<li><code><a title="graphAlgorithms.multiplex.build_network.reverse_relable_nodes" href="#graphAlgorithms.multiplex.build_network.reverse_relable_nodes">reverse_relable_nodes</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>