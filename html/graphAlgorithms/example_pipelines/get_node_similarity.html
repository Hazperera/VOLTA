<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.5" />
<title>graphAlgorithms.example_pipelines.get_node_similarity API documentation</title>
<meta name="description" content="This is an example pipeline on how to estimate the similarity between multiple networks
based on their similarity in shared nodes" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>graphAlgorithms.example_pipelines.get_node_similarity</code></h1>
</header>
<section id="section-intro">
<p>This is an example pipeline on how to estimate the similarity between multiple networks
based on their similarity in shared nodes</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This is an example pipeline on how to estimate the similarity between multiple networks
based on their similarity in shared nodes 
&#34;&#34;&#34;

import networkx as nx
import pandas as pd
import csv
import random
import sys
import graphAlgorithms.distances.global_distances as global_distances
import graphAlgorithms.distances.local as local
import graphAlgorithms.simplification as simplification
import graphAlgorithms.distances.trees as trees
import graphAlgorithms.distances.node_edge_similarities as node_edge_similarities
import pickle
from scipy.stats import kurtosis, skew, kendalltau
import statistics
import numpy as np
import scipy


def preprocess_graph(net_temp, attribute=&#34;weight&#34;, location = None, labels = None):
    &#34;&#34;&#34;
    function to convert list of networkx graph objects into list of sublist format as needed by
    these functions

    Input
        net_temp list of networkx graph objects if location is not None
            else needs to be list of paths to networkx edgelists (files need to end on .edgelist)

        weight edge attribute to be converted

        location is str of were output should be saved
            if None then a list of edgelists is returned else their pickled location is returned

        labels is list of network names in same order as in net_temp
            only needed if location is not None

    Output
        list of graph objects in edge list format or if location is not None list of path location of saved objects
    &#34;&#34;&#34;
    if location is None:
        networks = []
        for n in net_temp:
            temp = []
            edges = list(n.edges())
            for edge in edges:
                temp.append([edge[0], edge[1], n[edge[0]][edge[1]][attribute]])

            networks.append(temp)

        return networks

    else:
        networks = []
        for i in range(len(net_temp)):
            path = net_temp[i]
            name = labels[i]
            n=nx.read_weighted_edgelist(path)

            temp = []
            edges = list(n.edges())
            for edge in edges:
                temp.append([edge[0], edge[1], n[edge[0]][edge[1]][attribute]])

            
            #save converted
            print(&#34;save&#34;, name)
            with open(location + name+&#34;.pckl&#34;, &#34;wb&#34;) as f:
                pickle.dump(temp, f, protocol=4)

            networks.append(location + name+&#34;.pckl&#34;)

        return networks

def preprocess_node_list(networks, is_file = False, location = None, names= None):
    &#34;&#34;&#34;
    function to map nodes to ids for faster &amp; easier computation

    Input
        networks is list of edgelists as outputed by preprocess_graph()
            or list of file locations to python pickles of these objects (as saved when using preprocess_graph() with location not None)

        is_file if False then networks is list of networkx objects
            if True then networks is list of file locations to python pickles
                if True converted networks are saved as pickles to location
        location str to where converted networks should be saved - will only be used if is_file is True

        names list of network names in same order as networks

    Output
        list of converted networks (or str to saved location)
        dict of node to id mapping which can be used to reverse mapping

    &#34;&#34;&#34;
    if not is_file:
        for i in range(len(networks)):
            if i == 0:
                
                m, n = node_edge_similarities.map_node_to_id(networks[i], mapping={}, next_value=0)

            else:
                m, n = node_edge_similarities.map_node_to_id(networks[i], mapping=m, next_value=n)


        node_lists = []

        for net in networks:
            lst = list(dict.fromkeys(node_edge_similarities.construct_mapped_node(m, net)))
            node_lists.append(lst)
            

        return node_lists, m


    else:
        for i in range(len(networks)):
            #load file from disk
            
            with open(networks[i], &#34;rb&#34;) as f:
                net = pickle.load(f)

            if i % 10 == 0:
                print(&#34;loaded &#34;, i , &#34;network from disk out of &#34;, len(networks))

            if i == 0:
                
                m, n = node_edge_similarities.map_node_to_id(net, mapping={}, next_value=0)

            else:
                m, n = node_edge_similarities.map_node_to_id(net, mapping=m, next_value=n)

        
        node_lists = []
        for i in range(len(networks)):
            with open(networks[i], &#34;rb&#34;) as f:
                net = pickle.load(f)

            lst = list(dict.fromkeys(node_edge_similarities.construct_mapped_node(m, net)))
            #save
            name = names[i]

            with open(location + name+&#34;.pckl&#34;, &#34;wb&#34;) as f:
                pickle.dump(lst, f, protocol=4)

            print(&#34;saved&#34;)
            node_lists.append(location + name+&#34;.pckl&#34;)

            

        return node_lists, m


def sort_list_and_get_shared(node_lists, m, network_graphs, labels, degree=True, degree_centrality=True, closeness_centrality=True, betweenness=True, is_file = False):
    &#34;&#34;&#34;
    preprocessing function to sort edge list after weight

    Input
        output of preprocess_node_list
        mapping as returned by preprocess_node_list
        original list of networkx graph objects
        labels is list of str containing names of each layer for later identification

        if is_file is True then network_graphs contains file location instead of object
            
            network_graphs contains paths to networkx weighted edge lists

    Output
        list of networks containing sorted node list after degree, degree centrality, closeness centrality, betweenness, &amp; average of all
        list of shared edges between networks
        binary representation of networks nodes based on all possible nodes in all networks
    &#34;&#34;&#34;

    
    shared_nodes = node_edge_similarities.compute_shared_layers(node_lists, labels, mapping = None, weight=False)

    binary = node_edge_similarities.compute_binary_layer(shared_nodes, layers=labels)

    sorted_nodes = []
    saved_values = []
    
    if not is_file:
        for net in network_graphs:
            s, v = node_edge_similarities.sort_node_list(net, m, degree=degree, degree_centrality=degree_centrality, closeness_centrality=closeness_centrality, betweenness=betweenness,as_str=False)
            sorted_nodes.append(s)
            saved_values.append(v)

    else:
        for path in network_graphs:
            net = nx.read_weighted_edgelist(path)
            s, v = node_edge_similarities.sort_node_list(net, m, degree=degree, degree_centrality=degree_centrality, closeness_centrality=closeness_centrality, betweenness=betweenness,as_str=False)
            sorted_nodes.append(s)
            saved_values.append(v)


    return sorted_nodes, shared_nodes, binary, saved_values


def estimate_similarities_nodes(node_lists, sorted_nodes, binary,  kendall_x=50):
    &#34;&#34;&#34;
    function to estimate edge similarities

    Input
        output of preprocess_node_list

        sorted_nodes as returned by sort_list_and_get_shared

        binary as returned by sort_list_and_get_shared

        kendall_x number of edges to be considered in kendall ranking (top)

    Output
        numpy matrices containing

        jaccard similarity, jaccard distance, similarity
        kendall correlation for degree centrality, closeness centrality, betweenness, hamming distance
    &#34;&#34;&#34;

    j, s = node_edge_similarities.shared_elements_multiple(node_lists, labels=None, percentage=True, jaccard=True, jaccard_similarity = True, penalize_percentage=False)
    jd = node_edge_similarities.to_distance(j)

    print(&#34;kendall top&#34;)
    #ranked after degree centrality
    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;dc&#34;])
    kendall_dc_top ,b_dc_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;cc&#34;])
    kendall_cc_top ,b_cc_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;betweenness&#34;])
    kendall_betweenness_top ,b_b_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)


    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_mean&#34;])
    kendall_avg_top ,b_avg_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_median&#34;])
    kendall_med_top ,b_med_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)


    print(&#34;kendall bottom&#34;)
    #ranked after degree centrality
    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;dc&#34;])
    kendall_dc_bottom ,b_dc_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;cc&#34;])
    kendall_cc_bottom ,b_cc_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;betweenness&#34;])
    kendall_betweenness_bottom ,b_b_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)


    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_median&#34;])
    kendall_med_bottom ,b_med_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_mean&#34;])
    kendall_avg_bottom ,b_avg_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)




    hamming, p = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(binary, compute=&#34;hamming&#34;)

    smc, p = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(binary, compute=&#34;smc&#34;)

    return j, jd, s, kendall_dc_top, b_dc_top, kendall_cc_top, b_cc_top, kendall_betweenness_top, b_b_top, kendall_avg_top, b_avg_top, hamming, kendall_dc_bottom , b_dc_bottom , kendall_cc_bottom , b_cc_bottom , kendall_betweenness_bottom , b_b_bottom , kendall_avg_bottom , b_avg_bottom , smc, kendall_med_top, b_med_top, kendall_med_bottom, b_med_bottom</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="graphAlgorithms.example_pipelines.get_node_similarity.estimate_similarities_nodes"><code class="name flex">
<span>def <span class="ident">estimate_similarities_nodes</span></span>(<span>node_lists, sorted_nodes, binary, kendall_x=50)</span>
</code></dt>
<dd>
<section class="desc"><p>function to estimate edge similarities</p>
<p>Input
output of preprocess_node_list</p>
<pre><code>sorted_nodes as returned by sort_list_and_get_shared

binary as returned by sort_list_and_get_shared

kendall_x number of edges to be considered in kendall ranking (top)
</code></pre>
<p>Output
numpy matrices containing</p>
<pre><code>jaccard similarity, jaccard distance, similarity
kendall correlation for degree centrality, closeness centrality, betweenness, hamming distance
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_similarities_nodes(node_lists, sorted_nodes, binary,  kendall_x=50):
    &#34;&#34;&#34;
    function to estimate edge similarities

    Input
        output of preprocess_node_list

        sorted_nodes as returned by sort_list_and_get_shared

        binary as returned by sort_list_and_get_shared

        kendall_x number of edges to be considered in kendall ranking (top)

    Output
        numpy matrices containing

        jaccard similarity, jaccard distance, similarity
        kendall correlation for degree centrality, closeness centrality, betweenness, hamming distance
    &#34;&#34;&#34;

    j, s = node_edge_similarities.shared_elements_multiple(node_lists, labels=None, percentage=True, jaccard=True, jaccard_similarity = True, penalize_percentage=False)
    jd = node_edge_similarities.to_distance(j)

    print(&#34;kendall top&#34;)
    #ranked after degree centrality
    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;dc&#34;])
    kendall_dc_top ,b_dc_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;cc&#34;])
    kendall_cc_top ,b_cc_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;betweenness&#34;])
    kendall_betweenness_top ,b_b_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)


    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_mean&#34;])
    kendall_avg_top ,b_avg_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_median&#34;])
    kendall_med_top ,b_med_top,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;top&#34;, kendall_x = kendall_x)


    print(&#34;kendall bottom&#34;)
    #ranked after degree centrality
    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;dc&#34;])
    kendall_dc_bottom ,b_dc_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;cc&#34;])
    kendall_cc_bottom ,b_cc_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;betweenness&#34;])
    kendall_betweenness_bottom ,b_b_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)


    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_median&#34;])
    kendall_med_bottom ,b_med_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)

    current_sorted = []
    for di in sorted_nodes:
            current_sorted.append(di[&#34;average_mean&#34;])
    kendall_avg_bottom ,b_avg_bottom,x = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(current_sorted, compute=&#34;kendall&#34;, kendall_usage=&#34;bottom&#34;, kendall_x = kendall_x)




    hamming, p = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(binary, compute=&#34;hamming&#34;)

    smc, p = node_edge_similarities.build_similarity_matrix_for_binary_and_ranked(binary, compute=&#34;smc&#34;)

    return j, jd, s, kendall_dc_top, b_dc_top, kendall_cc_top, b_cc_top, kendall_betweenness_top, b_b_top, kendall_avg_top, b_avg_top, hamming, kendall_dc_bottom , b_dc_bottom , kendall_cc_bottom , b_cc_bottom , kendall_betweenness_bottom , b_b_bottom , kendall_avg_bottom , b_avg_bottom , smc, kendall_med_top, b_med_top, kendall_med_bottom, b_med_bottom</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.example_pipelines.get_node_similarity.preprocess_graph"><code class="name flex">
<span>def <span class="ident">preprocess_graph</span></span>(<span>net_temp, attribute='weight', location=None, labels=None)</span>
</code></dt>
<dd>
<section class="desc"><p>function to convert list of networkx graph objects into list of sublist format as needed by
these functions</p>
<p>Input
net_temp list of networkx graph objects if location is not None
else needs to be list of paths to networkx edgelists (files need to end on .edgelist)</p>
<pre><code>weight edge attribute to be converted

location is str of were output should be saved
    if None then a list of edgelists is returned else their pickled location is returned

labels is list of network names in same order as in net_temp
    only needed if location is not None
</code></pre>
<p>Output
list of graph objects in edge list format or if location is not None list of path location of saved objects</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_graph(net_temp, attribute=&#34;weight&#34;, location = None, labels = None):
    &#34;&#34;&#34;
    function to convert list of networkx graph objects into list of sublist format as needed by
    these functions

    Input
        net_temp list of networkx graph objects if location is not None
            else needs to be list of paths to networkx edgelists (files need to end on .edgelist)

        weight edge attribute to be converted

        location is str of were output should be saved
            if None then a list of edgelists is returned else their pickled location is returned

        labels is list of network names in same order as in net_temp
            only needed if location is not None

    Output
        list of graph objects in edge list format or if location is not None list of path location of saved objects
    &#34;&#34;&#34;
    if location is None:
        networks = []
        for n in net_temp:
            temp = []
            edges = list(n.edges())
            for edge in edges:
                temp.append([edge[0], edge[1], n[edge[0]][edge[1]][attribute]])

            networks.append(temp)

        return networks

    else:
        networks = []
        for i in range(len(net_temp)):
            path = net_temp[i]
            name = labels[i]
            n=nx.read_weighted_edgelist(path)

            temp = []
            edges = list(n.edges())
            for edge in edges:
                temp.append([edge[0], edge[1], n[edge[0]][edge[1]][attribute]])

            
            #save converted
            print(&#34;save&#34;, name)
            with open(location + name+&#34;.pckl&#34;, &#34;wb&#34;) as f:
                pickle.dump(temp, f, protocol=4)

            networks.append(location + name+&#34;.pckl&#34;)

        return networks</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.example_pipelines.get_node_similarity.preprocess_node_list"><code class="name flex">
<span>def <span class="ident">preprocess_node_list</span></span>(<span>networks, is_file=False, location=None, names=None)</span>
</code></dt>
<dd>
<section class="desc"><p>function to map nodes to ids for faster &amp; easier computation</p>
<p>Input
networks is list of edgelists as outputed by preprocess_graph()
or list of file locations to python pickles of these objects (as saved when using preprocess_graph() with location not None)</p>
<pre><code>is_file if False then networks is list of networkx objects
    if True then networks is list of file locations to python pickles
        if True converted networks are saved as pickles to location
location str to where converted networks should be saved - will only be used if is_file is True

names list of network names in same order as networks
</code></pre>
<p>Output
list of converted networks (or str to saved location)
dict of node to id mapping which can be used to reverse mapping</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_node_list(networks, is_file = False, location = None, names= None):
    &#34;&#34;&#34;
    function to map nodes to ids for faster &amp; easier computation

    Input
        networks is list of edgelists as outputed by preprocess_graph()
            or list of file locations to python pickles of these objects (as saved when using preprocess_graph() with location not None)

        is_file if False then networks is list of networkx objects
            if True then networks is list of file locations to python pickles
                if True converted networks are saved as pickles to location
        location str to where converted networks should be saved - will only be used if is_file is True

        names list of network names in same order as networks

    Output
        list of converted networks (or str to saved location)
        dict of node to id mapping which can be used to reverse mapping

    &#34;&#34;&#34;
    if not is_file:
        for i in range(len(networks)):
            if i == 0:
                
                m, n = node_edge_similarities.map_node_to_id(networks[i], mapping={}, next_value=0)

            else:
                m, n = node_edge_similarities.map_node_to_id(networks[i], mapping=m, next_value=n)


        node_lists = []

        for net in networks:
            lst = list(dict.fromkeys(node_edge_similarities.construct_mapped_node(m, net)))
            node_lists.append(lst)
            

        return node_lists, m


    else:
        for i in range(len(networks)):
            #load file from disk
            
            with open(networks[i], &#34;rb&#34;) as f:
                net = pickle.load(f)

            if i % 10 == 0:
                print(&#34;loaded &#34;, i , &#34;network from disk out of &#34;, len(networks))

            if i == 0:
                
                m, n = node_edge_similarities.map_node_to_id(net, mapping={}, next_value=0)

            else:
                m, n = node_edge_similarities.map_node_to_id(net, mapping=m, next_value=n)

        
        node_lists = []
        for i in range(len(networks)):
            with open(networks[i], &#34;rb&#34;) as f:
                net = pickle.load(f)

            lst = list(dict.fromkeys(node_edge_similarities.construct_mapped_node(m, net)))
            #save
            name = names[i]

            with open(location + name+&#34;.pckl&#34;, &#34;wb&#34;) as f:
                pickle.dump(lst, f, protocol=4)

            print(&#34;saved&#34;)
            node_lists.append(location + name+&#34;.pckl&#34;)

            

        return node_lists, m</code></pre>
</details>
</dd>
<dt id="graphAlgorithms.example_pipelines.get_node_similarity.sort_list_and_get_shared"><code class="name flex">
<span>def <span class="ident">sort_list_and_get_shared</span></span>(<span>node_lists, m, network_graphs, labels, degree=True, degree_centrality=True, closeness_centrality=True, betweenness=True, is_file=False)</span>
</code></dt>
<dd>
<section class="desc"><p>preprocessing function to sort edge list after weight</p>
<p>Input
output of preprocess_node_list
mapping as returned by preprocess_node_list
original list of networkx graph objects
labels is list of str containing names of each layer for later identification</p>
<pre><code>if is_file is True then network_graphs contains file location instead of object

    network_graphs contains paths to networkx weighted edge lists
</code></pre>
<p>Output
list of networks containing sorted node list after degree, degree centrality, closeness centrality, betweenness, &amp; average of all
list of shared edges between networks
binary representation of networks nodes based on all possible nodes in all networks</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort_list_and_get_shared(node_lists, m, network_graphs, labels, degree=True, degree_centrality=True, closeness_centrality=True, betweenness=True, is_file = False):
    &#34;&#34;&#34;
    preprocessing function to sort edge list after weight

    Input
        output of preprocess_node_list
        mapping as returned by preprocess_node_list
        original list of networkx graph objects
        labels is list of str containing names of each layer for later identification

        if is_file is True then network_graphs contains file location instead of object
            
            network_graphs contains paths to networkx weighted edge lists

    Output
        list of networks containing sorted node list after degree, degree centrality, closeness centrality, betweenness, &amp; average of all
        list of shared edges between networks
        binary representation of networks nodes based on all possible nodes in all networks
    &#34;&#34;&#34;

    
    shared_nodes = node_edge_similarities.compute_shared_layers(node_lists, labels, mapping = None, weight=False)

    binary = node_edge_similarities.compute_binary_layer(shared_nodes, layers=labels)

    sorted_nodes = []
    saved_values = []
    
    if not is_file:
        for net in network_graphs:
            s, v = node_edge_similarities.sort_node_list(net, m, degree=degree, degree_centrality=degree_centrality, closeness_centrality=closeness_centrality, betweenness=betweenness,as_str=False)
            sorted_nodes.append(s)
            saved_values.append(v)

    else:
        for path in network_graphs:
            net = nx.read_weighted_edgelist(path)
            s, v = node_edge_similarities.sort_node_list(net, m, degree=degree, degree_centrality=degree_centrality, closeness_centrality=closeness_centrality, betweenness=betweenness,as_str=False)
            sorted_nodes.append(s)
            saved_values.append(v)


    return sorted_nodes, shared_nodes, binary, saved_values</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="graphAlgorithms.example_pipelines" href="index.html">graphAlgorithms.example_pipelines</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="graphAlgorithms.example_pipelines.get_node_similarity.estimate_similarities_nodes" href="#graphAlgorithms.example_pipelines.get_node_similarity.estimate_similarities_nodes">estimate_similarities_nodes</a></code></li>
<li><code><a title="graphAlgorithms.example_pipelines.get_node_similarity.preprocess_graph" href="#graphAlgorithms.example_pipelines.get_node_similarity.preprocess_graph">preprocess_graph</a></code></li>
<li><code><a title="graphAlgorithms.example_pipelines.get_node_similarity.preprocess_node_list" href="#graphAlgorithms.example_pipelines.get_node_similarity.preprocess_node_list">preprocess_node_list</a></code></li>
<li><code><a title="graphAlgorithms.example_pipelines.get_node_similarity.sort_list_and_get_shared" href="#graphAlgorithms.example_pipelines.get_node_similarity.sort_list_and_get_shared">sort_list_and_get_shared</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.5</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>