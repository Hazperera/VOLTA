{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphAlgorithms as ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to compare two networks in detail in order to investigate if specific nodes (genes) / gene areas are changing/ are affected by the condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location where the raw data files are stored, it is set to run from the installation folder\n",
    "#- if applicable please change or CHANGE to the location of your networks\n",
    "\n",
    "graph_location = \"../networks/edgelists/\"\n",
    "\n",
    "#location where output should be saved\n",
    "#Please set location\n",
    "location = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below an example on how to load an Edgelist with column headings into a NetworkX Graph object\n",
    "\n",
    "There are multiple examples on how to load different formats in the import and export networks notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = []\n",
    "networks_graphs = []\n",
    "cnt = 0\n",
    "print(\"load networks\")\n",
    "#gets all files located in the specified folder that end on .edgelist\n",
    "#CHANGE the ending if your files end differently\n",
    "for path in glob.glob(graph_location +\"*.edgelist\"):\n",
    "    if cnt < 2:\n",
    "        #you can specify that only part of the file name should be used as network name for later identification\n",
    "        name =  path.split(\"/\")[-1].replace(\".rds.edgelist\", \"\")\n",
    "\n",
    "\n",
    "        #read the edgelist file as a dataframe\n",
    "        fh = pd.read_csv(path, sep=\"\\t\")\n",
    "        #convert it into a NetworkX graph G and specify the column names of the node pairs\n",
    "        G=nx.from_pandas_edgelist(fh, \"V1\", \"V2\")\n",
    "\n",
    "        #if you have an unweighted network assign all edges the same edge weight - here a value of 1 is assigned\n",
    "        for u, v, d in G.edges(data=True):\n",
    "            d['weight'] = 1\n",
    "\n",
    "\n",
    "        #save the graph objects to a list (only suitable if small networks are processed)\n",
    "        #this is the main objects used for the examples below, which contains all networks\n",
    "        networks_graphs.append(G)\n",
    "        labels.append(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"loaded\", name)\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the networks into the used format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ga.get_node_similarity.preprocess_graph(networks_graphs, attribute=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get union of all nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for net in networks_graphs:\n",
    "    for node in net.nodes():\n",
    "        if node not in nodes:\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapp node names to ID (this is mainly used for node & edge similarity functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_lists, mapping = ga.get_node_similarity.preprocess_node_list(networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save mapping for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(location + \"node_id_mapping_network_network.pckl\", \"wb\") as f:\n",
    "    pickle.dump(mapping, f, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: create reversed mapping object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = ga.distances.node_edge_similarities.reverse_node_edge_mapping(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes\n",
    "\n",
    "we compare based on different centrality measures how the node location in the network changes and which nodes are the most similar or most different ones.\n",
    "Here we make use of the centrality ranks (as also estimated in the Network clustering pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nodes = []\n",
    "\n",
    "for graph in networks_graphs:\n",
    "    temp = ga.distances.node_edge_similarities.sort_node_list(graph, mapping, degree_centrality=True, closeness_centrality=True, betweenness=True, k=None, as_str=False)\n",
    "    \n",
    "    sorted_nodes.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nodes[0][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert dict output to a dataframe to be more human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_ids = list(mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(mapping_ids, \n",
    "               columns =['Mapping ID']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the reversed mapping IDS (original node IDs - here they are Entrez IDs)\n",
    "entrez = []\n",
    "for g in mapping_ids:\n",
    "    entrez.append(reverse_mapping[g])\n",
    "df[\"Entrez IDs\"] = entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sorted_nodes)):\n",
    "    item = sorted_nodes[i][0]\n",
    "    for key in item.keys():\n",
    "        #ignore \"degree\" key, since it has not been calculated. We are using degree centrality instead.\n",
    "        if key != \"degree\":\n",
    "            temp = []\n",
    "            for g in mapping_ids:\n",
    "                for xx in range(len(item[key])):\n",
    "                    if item[key][xx] == g:\n",
    "                        temp.append(xx)\n",
    "                \n",
    "            #add to dataframe\n",
    "            #since the results are in the same order as the network labels \n",
    "            #we can use the network label directly as column heading\n",
    "            df[labels[i]+\" Ranking \" + key] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interessted in knowing which genes change the most between the networks with regards to their network position. Therefore we are going to estimate the rank difference of the median ranks.\n",
    "This can be done for any of the other parameters as well if it is needed for your analysis in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = []\n",
    "\n",
    "for g in mapping_ids:\n",
    "    \n",
    "    val1 = df.loc[df[\"Mapping ID\"] == g][labels[0]+\" Ranking average_median\"].to_list()[0]\n",
    "    \n",
    "    val2 = df.loc[df[\"Mapping ID\"] == g][labels[1]+\" Ranking average_median\"].to_list()[0]\n",
    "    \n",
    "    change.append(abs(val1-val2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_change = pd.DataFrame(list(zip(mapping_ids, entrez, change, df[labels[0]+\" Ranking average_median\"].to_list(), df[labels[1]+\" Ranking average_median\"].to_list())), \n",
    "               columns =['Mapping ID', 'Entrez IDs', 'Absolute Ranking Difference', labels[0]+' Ranking average_median', labels[1]+' Ranking average_median' ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_change = df_change.sort_values(by =[\"Absolute Ranking Difference\"], axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 top genes, which network position changes the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_change.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 top most similar genes, with regards to their network position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_change.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These genes could now for example be functionally enriched or a GSEA could be performed on them (combined or individually)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO? Should enrichment be done externally or should we include e.g. the API call to the panther enrichment tool? or simply show the code here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges\n",
    "\n",
    "Which edges are common in the 2 networks, which edges are unique to one network. And which edges network position (betweenness) changes the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate edge betweenness scores and assign them to the graph objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sort edges after edge betweenness\")\n",
    "bet = []\n",
    "graphs_with_betweenness = []\n",
    "for net in networks_graphs:\n",
    "    edges_betweenness = nx.edge_betweenness_centrality(net)\n",
    "    bet.append(edges_betweenness)\n",
    "    #write as new attribute to graph\n",
    "    temp = nx.set_edge_attributes(net, edges_betweenness, \"betweenness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the networks & map edges to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ga.get_edge_similarity.preprocess_graph(networks_graphs, attribute=\"betweenness\")\n",
    "\n",
    "print(\"map edges to id\")\n",
    "\n",
    "network_lists, mapping = ga.get_edge_similarity.preprocess_edge_list(networks)\n",
    "\n",
    "with open(location + \"edge_id_mapping_network_network.pckl\", \"wb\") as f:\n",
    "    pickle.dump(mapping, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = ga.distances.node_edge_similarities.reverse_node_edge_mapping(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get shared edges. Returns a dict, where key is mapped edge ID and value is list of network names this edge is present in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared = ga.distances.node_edge_similarities.compute_shared_layers(network_lists, labels, is_file=False, in_async=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to a dataframe to be more human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(reverse_mapping.values())\n",
    "edge_mapped_IDs = list(reverse_mapping.keys())\n",
    "\n",
    "df = pd.DataFrame(list(zip(edges, edge_mapped_IDs)), \n",
    "               columns =['Edges', 'Mapping ID']) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    temp = []\n",
    "    for i in edge_mapped_IDs:\n",
    "        if label in shared[i]:\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "            \n",
    "    df[\"In \"+label] = temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all edges that are in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_df = df.loc[(df[\"In \"+labels[0]] == 1) & (df[\"In \"+labels[1]] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example you can now functional enrich the genes making up the consistent edges. Or see if this edges belong to some specific modules in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select unique edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = df.loc[((df[\"In \"+labels[0]] == 1) & (df[\"In \"+labels[1]] == 0)) | ((df[\"In \"+labels[0]] == 0) & (df[\"In \"+labels[1]] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: enrichment / mapping to modules?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node areas/ connectivity\n",
    "\n",
    "which nodes are connected in a similar way and which node areas are different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random walks\n",
    "\n",
    "For each common node in the 2 networks random walks are performed and their similarity in visited nodes is compared. This allows to identify the most similar/ dissimilar node areas.\n",
    "\n",
    "For each node 10 * its degree random walks of size 5 are performed. A smaller walk size \"scans\" a smaller area around the starting node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performed_walks = ga.get_walk_distances.helper_walks(networks_graphs, nodes, labels, steps=5, number_of_walks=10, degree=True, probabilistic=False, weight =\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are estimating for each starting node how often surrounding nodes/ edges have been visit w.r.t. all the visited nodes/ edges. Depending on your network sizes and selected nodes this can be quite memory intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_counts, edge_counts, nodes_frc, edges_frc = ga.get_walk_distances.helper_get_counts(labels, networks_graphs, performed_walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to estimate network similarities based on the visited nodes. For each network pair, kendall rank correlation is calculated (of the top 20 nodes) for the same starting node. The mean correlation value of all same node pairs for a network pair is estimated as well as the individual values are calculated and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_edges, results_nodes, results_edges_p, results_nodes_p, results_edges_all, results_nodes_all, results_edges_p_all, results_nodes_p_all = ga.get_walk_distances.helper_walk_sim(networks_graphs, performed_walks, nodes, labels, top=20, undirected=False, return_all = True, nodes_ranked=nodes_frc, edges_ranked=edges_frc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map results to a dataframe\n",
    "df = pd.DataFrame(list(zip(nodes, results_nodes_all[(labels[0], labels[1])])), \n",
    "               columns =['Entrez ID', 'Correlation']) \n",
    "\n",
    "#sort after correlation\n",
    "\n",
    "df = df.sort_values(by =[\"Correlation\"], axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Nodes in this areas can again be functionally enriched and/ or their modules can be investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabable remove from here on!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community/ Module detection\n",
    "\n",
    "We will detect modules in the graphs and map the previously identified similar/ dissimilar areas to them.\n",
    "Here we will only use a simple community detection method. For more algorithms, evaluation and ensembl methods please refer to the Community notebook.\n",
    "\n",
    "For the example the walktrap algorithm is used, which is based on non probabilistic random walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "communities = []\n",
    "\n",
    "for graph in networks_graphs:\n",
    "    c = ga.communities.walktrap(graph, return_object=False)\n",
    "    #convert into another format\n",
    "    con = ga.communities.convert_communities(c)\n",
    "    \n",
    "    communities.append(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar are the detected communities/ modules w.r.t their nodes?\n",
    "\n",
    "To answer this we transform each community into a subgraph and compare their nodes (if they have at least 1 edge).\n",
    "For similar modules the edges can be compared as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = []\n",
    "com_labels = []\n",
    "for i in range(len(communities)):\n",
    "    com = communities[i]\n",
    "    graph = networks_graphs[i]\n",
    "    \n",
    "    for k in com.keys():\n",
    "        if len(graph.subgraph(com[k]).edges()) > 1:\n",
    "            subgraphs.append(graph.subgraph(com[k]))\n",
    "       \n",
    "            com_labels.append(labels[i]+\"_\"+str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the same functions as applied in the Nodes section in the Network clustering notebook. For explanations refer to this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_networks = ga.get_node_similarity.preprocess_graph(subgraphs, attribute=\"weight\")\n",
    "\n",
    "sub_network_lists, sub_mapping = ga.get_node_similarity.preprocess_node_list(sub_networks)\n",
    "\n",
    "with open(location + \"node_id_mapping_subgraphs.pckl\", \"wb\") as f:\n",
    "    pickle.dump(sub_mapping, f, protocol=4)\n",
    "    \n",
    "sorted_nodes, shared_nodes, binary, centrality_values = ga.get_node_similarity.sort_list_and_get_shared(sub_network_lists, sub_mapping, subgraphs, com_labels, degree_centrality=True, closeness_centrality=True, betweenness=True, degree=False, in_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jd, per = ga.node_edge_similarities.shared_elements_multiple(sub_network_lists, labels=com_labels, percentage=True, jaccard=True, jaccard_similarity=False, in_async=False, is_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the communities in the different networks contain similar nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))  \n",
    "\n",
    "sns.heatmap(jd, annot=False, ax=ax, xticklabels=com_labels, yticklabels=com_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))  \n",
    "\n",
    "sns.heatmap(per, annot=False, ax=ax, xticklabels=com_labels, yticklabels=com_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
