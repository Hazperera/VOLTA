{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphAlgorithms as ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pipeline we are making use of the network clustering estimated in the Network clustering example pipeline.\n",
    "\n",
    "The aim is to identify graph structures that are common or statistically overrepressented in the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location where the raw data files are stored, it is set to run from the installation folder\n",
    "#- if applicable please change or CHANGE to the location of your networks\n",
    "\n",
    "graph_location = \"../networks/edgelists/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location where output should be saved\n",
    "#Please set location\n",
    "location = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below an example on how to load an Edgelist with column headings into a NetworkX Graph object\n",
    "\n",
    "There are multiple examples on how to load different formats in the import and export networks notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = []\n",
    "networks_graphs = []\n",
    "cnt = 0\n",
    "print(\"load networks\")\n",
    "#gets all files located in the specified folder that end on .edgelist\n",
    "#CHANGE the ending if your files end differently\n",
    "for path in glob.glob(graph_location +\"*.edgelist\"):\n",
    "    \n",
    "        #you can specify that only part of the file name should be used as network name for later identification\n",
    "        name =  path.split(\"/\")[-1].replace(\".rds.edgelist\", \"\")\n",
    "\n",
    "\n",
    "        #read the edgelist file as a dataframe\n",
    "        fh = pd.read_csv(path, sep=\"\\t\")\n",
    "        #convert it into a NetworkX graph G and specify the column names of the node pairs\n",
    "        G=nx.from_pandas_edgelist(fh, \"V1\", \"V2\")\n",
    "\n",
    "        #if you have an unweighted network assign all edges the same edge weight - here a value of 1 is assigned\n",
    "        for u, v, d in G.edges(data=True):\n",
    "            d['weight'] = 1\n",
    "\n",
    "\n",
    "        #save the graph objects to a list (only suitable if small networks are processed)\n",
    "        #this is the main objects used for the examples below, which contains all networks\n",
    "        networks_graphs.append(G)\n",
    "        labels.append(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"loaded\", name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for net in networks_graphs:\n",
    "    for node in net.nodes():\n",
    "        if node not in nodes:\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load clustering estimated in Network clustering pipeline\n",
    "\n",
    "TODO: change location and have intermediate results on gitlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = pd.read_csv(location+\"clustering_networks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform to a dict, where key is cluster ID and value is list of NetworkX graph objects in that cluster or its adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_networks = {}\n",
    "clusters_adjacencymatrices = {}\n",
    "for cl in list(Counter(clustering[\"CLUSTER\"].to_list()).keys()):\n",
    "    clusters_networks[cl] = []\n",
    "    clusters_adjacencymatrices[cl] = []\n",
    "\n",
    "for cl in list(Counter(clustering[\"CLUSTER\"].to_list()).keys()):\n",
    "    #get all drug names and their ids in this cluster\n",
    "    \n",
    "    t = clustering.loc[clustering[\"CLUSTER\"]==cl]\n",
    "    \n",
    "    drugs = t[\"CHEMICAL\"].to_list()\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for d in drugs:\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == d:\n",
    "                temp.append(networks_graphs[i])\n",
    "                temp2.append(nx.to_numpy_matrix(networks_graphs[i], nodelist=nodes,  weight='weight'))\n",
    "    clusters_networks[cl] = temp\n",
    "    clusters_adjacencymatrices[cl] = temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate common subgraphs \n",
    "\n",
    "If an edge is in p fraction of all networks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which edges are in 75% of all graphs in a cluster?\n",
    "\n",
    "common_75 = {}\n",
    "\n",
    "for cl in clusters_adjacencymatrices.keys():\n",
    "    common_75[cl] = ga.pattern_matching.get_common_subgraph(clusters_adjacencymatrices[cl], p=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the common sub-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in common_75.keys():\n",
    "    print(\"cluster \", i)\n",
    "    T = ga.pattern_matching.build_graph_remove_isolates(common_75[i])\n",
    "    \n",
    "    plt.figure(3,figsize=(5,5)) \n",
    "    nx.draw(T, with_labels = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which edges are in 50% of all graphs in a cluster?\n",
    "\n",
    "common_50 = {}\n",
    "\n",
    "for cl in clusters_adjacencymatrices.keys():\n",
    "    common_50[cl] = ga.pattern_matching.get_common_subgraph(clusters_adjacencymatrices[cl], p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in common_50.keys():\n",
    "    print(\"cluster \", i)\n",
    "    T = ga.pattern_matching.build_graph_remove_isolates(common_50[i])\n",
    "    \n",
    "    plt.figure(3,figsize=(5,5)) \n",
    "    nx.draw(T, with_labels = False, node_size = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is easy and provides a fast overview if networks withing a cluster share many edges or not, but does not provide any information about the edge distribution within a cluster and between clusters.\n",
    "\n",
    "\n",
    "Therefore next we are estimating a subgraph based on if a specific edge within a cluster is statistically significant enriched in that cluster. The function estimates p values for each edge within a cluster based on a hypergeometric function and performs correction based on a Benjamin Hochberg correction. Both values are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_matrix, adj_pval_matrix = ga.pattern_matching.get_statistical_overrepresented_edges(clusters_adjacencymatrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in adj_pval_matrix.keys():\n",
    "    print(\"cluster \", i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    T = ga.pattern_matching.build_graph_remove_isolates(adj_pval_matrix[i])\n",
    "    print(\"number nodes\", len(T.nodes()))\n",
    "    print(\"number edges\", len(T.edges()))\n",
    "    plt.figure(3,figsize=(15,15)) \n",
    "    nx.draw(T, with_labels = False, node_size = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated subgraphs can be used in replacement for all networks withing a cluster. Nodes & edges can be directly compared as described in network-network comparison or modules can be detected and functionally enriched as described in community detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communities\n",
    "\n",
    "Here consensus communities on all graphs within a network group as well as statistical overrepresented communities within a network group are calculated.\n",
    "For individual community detection algorithms or ensembl methods as well as on their application on individual networks please refer to the community detection example file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical overrepressented communities within a network group\n",
    "\n",
    "TODO: test updated function from package + try with provided partitioning based on another algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statistical_communities = ga.pattern_matching.get_statistical_overrepresented_communities(clusters_networks, nodes, pval=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there statistical enriched communities with at least 20 nodes per cluster? What are their nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_communities = {}\n",
    "\n",
    "for cl in statistical_communities.keys():\n",
    "    stat_communities[cl] = {}\n",
    "    print(\"cluster\", cl)\n",
    "    for c in Counter(statistical_communities[cl]).keys():\n",
    "        if Counter(statistical_communities[cl])[c] >= 20:\n",
    "            print(\"community \", c, \"has\", Counter(statistical_communities[cl])[c], \"nodes\")\n",
    "            \n",
    "            \n",
    "            temp = []\n",
    "            for i in range(len(nodes)):\n",
    "                if statistical_communities[cl][i] == c:\n",
    "                    temp.append(nodes[i])\n",
    "                    \n",
    "            stat_communities[cl][c] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These communities can now for example be functionally enriched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus Community on a group of networks\n",
    "\n",
    "For each network Louvain community detection is performed 10 times. Out of the partitionings for all networks in a group a consensus is estimated. The consensus is estimated based on clustering.consensus_clustering(), as explained in more detail in the Network clustering pipeline.\n",
    "\n",
    "TODO: try with modified function and provided pre-estimated communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus = {}\n",
    "\n",
    "for cl in clusters_networks.keys():\n",
    "    cons = ga.pattern_matching.get_consensus_community(clusters_networks[cl], nodes,  rep_network=10, threshold=0.75)\n",
    "    \n",
    "    consensus[cl] = cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the communities can be functionally enriched and compared between the clusters.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
