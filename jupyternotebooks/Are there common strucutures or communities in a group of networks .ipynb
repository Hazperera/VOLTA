{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphAlgorithms as ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pipeline we are making use of the network clustering estimated in the Network clustering example pipeline.\n",
    "\n",
    "The aim is to identify graph structures that are common among clusters or statistically overrepressented in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Preprocess Network\n",
    "\n",
    "First step of the pipeline consists in loading the chosen data set.\n",
    "You can store your networks in any common format, however the xx package requires that the networks are provided as NetworkX Graph objects (refer to its documentation for detailed instructions). Moreover, the networks should be weighted: if you have an unweighted network, then assign all edges the same edge weight. The package assumes \"weight\" to be the default edge weight label, but this can be set when needed.\n",
    "\n",
    "An example on how to pre-process a network, stored as an edgelist, is provided below. Different loading and storing examples are provided in the \"import and export of networks\" jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location where the raw data files are stored, it is set to run from the installation folder\n",
    "#- if applicable please change or CHANGE to the location of your networks\n",
    "\n",
    "graph_location = \"../networks/edgelists/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location where output should be saved\n",
    "#Please set location\n",
    "location = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = []\n",
    "networks_graphs = []\n",
    "cnt = 0\n",
    "print(\"load networks\")\n",
    "#gets all files located in the specified folder that end on .edgelist\n",
    "#CHANGE the ending if your files end differently\n",
    "for path in glob.glob(graph_location +\"*.edgelist\"):\n",
    "    \n",
    "        #you can specify that only part of the file name should be used as network name for later identification\n",
    "        name =  path.split(\"/\")[-1].replace(\".rds.edgelist\", \"\")\n",
    "\n",
    "\n",
    "        #read the edgelist file as a dataframe\n",
    "        fh = pd.read_csv(path, sep=\"\\t\")\n",
    "        #convert it into a NetworkX graph G and specify the column names of the node pairs\n",
    "        G=nx.from_pandas_edgelist(fh, \"V1\", \"V2\")\n",
    "\n",
    "        #if you have an unweighted network assign all edges the same edge weight - here a value of 1 is assigned\n",
    "        for u, v, d in G.edges(data=True):\n",
    "            d['weight'] = 1\n",
    "\n",
    "\n",
    "        #save the graph objects to a list (only suitable if small networks are processed)\n",
    "        #this is the main objects used for the examples below, which contains all networks\n",
    "        networks_graphs.append(G)\n",
    "        labels.append(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"loaded\", name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the union og nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for net in networks_graphs:\n",
    "    for node in net.nodes():\n",
    "        if node not in nodes:\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load clustering estimated in Network clustering pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It reads in the dataframe (stored as csv) created in the network clustering pipeline and stored in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = pd.read_csv(location+\"clustering_networks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to a dictionary (a data stracture in python that is more generally known as an associative array) where key is cluster ID and value is list of NetworkX graph objects in that cluster or its adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_networks = {}\n",
    "clusters_adjacencymatrices = {}\n",
    "for cl in list(Counter(clustering[\"CLUSTER\"].to_list()).keys()):\n",
    "    clusters_networks[cl] = []\n",
    "    clusters_adjacencymatrices[cl] = []\n",
    "\n",
    "for cl in list(Counter(clustering[\"CLUSTER\"].to_list()).keys()):\n",
    "    #get all drug names and their ids in this cluster\n",
    "    \n",
    "    t = clustering.loc[clustering[\"CLUSTER\"]==cl]\n",
    "    \n",
    "    drugs = t[\"CHEMICAL\"].to_list()\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for d in drugs:\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == d:\n",
    "                temp.append(networks_graphs[i])\n",
    "                temp2.append(nx.to_numpy_matrix(networks_graphs[i], nodelist=nodes,  weight='weight'))\n",
    "    clusters_networks[cl] = temp\n",
    "    clusters_adjacencymatrices[cl] = temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate common subgraphs \n",
    "\n",
    "Here we show an example of how to estimate sxubgraphs in case not all the edges are present in all the networks. In detail we show how to estimate the edges present in 75% and 50 % of the networks, respectively. For each of them, the common subnetwork is printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which edges are in 75% of all graphs in a cluster?\n",
    "\n",
    "common_75 = {}\n",
    "\n",
    "for cl in clusters_adjacencymatrices.keys():\n",
    "    common_75[cl] = ga.pattern_matching.get_common_subgraph(clusters_adjacencymatrices[cl], p=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the common subnetwork\n",
    "for i in common_75.keys():\n",
    "    print(\"cluster \", i)\n",
    "    T = ga.pattern_matching.build_graph_remove_isolates(common_75[i])\n",
    "    \n",
    "    plt.figure(3,figsize=(5,5)) \n",
    "    nx.draw(T, with_labels = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which edges are in 50% of all graphs in a cluster?\n",
    "\n",
    "common_50 = {}\n",
    "\n",
    "for cl in clusters_adjacencymatrices.keys():\n",
    "    common_50[cl] = ga.pattern_matching.get_common_subgraph(clusters_adjacencymatrices[cl], p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the subnetwork\n",
    "for i in common_50.keys():\n",
    "    print(\"cluster \", i)\n",
    "    T = ga.pattern_matching.build_graph_remove_isolates(common_50[i])\n",
    "    \n",
    "    plt.figure(3,figsize=(5,5)) \n",
    "    nx.draw(T, with_labels = False, node_size = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is easy and provides a fast overview if networks withing a cluster share many edges or not, but does not provide any information about the edge distribution within a cluster and between clusters.\n",
    "\n",
    "\n",
    "Therefore next we are estimating a subgraph based on if a specific edge within a cluster is statistically significant enriched in that cluster. The function estimates p values for each edge within a cluster based on a hypergeometric function and performs correction based on a Benjamin Hochberg correction. Both values are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_matrix, adj_pval_matrix = ga.pattern_matching.get_statistical_overrepresented_edges(clusters_adjacencymatrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in adj_pval_matrix.keys():\n",
    "    print(\"cluster \", i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    T = ga.pattern_matching.build_graph_remove_isolates(adj_pval_matrix[i])\n",
    "    print(\"number nodes\", len(T.nodes()))\n",
    "    print(\"number edges\", len(T.edges()))\n",
    "    plt.figure(3,figsize=(15,15)) \n",
    "    nx.draw(T, with_labels = False, node_size = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated subgraphs can be used in replacement for all networks withing a cluster. Nodes & edges can be directly compared as described in the network-network comparison pipeline or modules can be detected and functionally enriched as described in the community detection example file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communities\n",
    "\n",
    "Here, we calculate consensus communities between all graphs within a network group, as well as we evaluate statistical overrepresented communities.\n",
    "For individual community detection algorithms or ensembl methods, as well as on their application on individual networks, please refer to the community detection example file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical overrepressented communities within a network group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statistical_communities = ga.pattern_matching.get_statistical_overrepresented_communities(clusters_networks, nodes, pval=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the enriched comunities are calculated, we assured that they were populated by at least 20 nodes (adjust this value to your needs e.g. what size is required to perform enrichment?), and proceeded to retrieve them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_communities = {}\n",
    "\n",
    "for cl in statistical_communities.keys():\n",
    "    stat_communities[cl] = {}\n",
    "    print(\"cluster\", cl)\n",
    "    for c in Counter(statistical_communities[cl]).keys():\n",
    "        if Counter(statistical_communities[cl])[c] >= 20:\n",
    "            print(\"community \", c, \"has\", Counter(statistical_communities[cl])[c], \"nodes\")\n",
    "            \n",
    "            \n",
    "            temp = []\n",
    "            for i in range(len(nodes)):\n",
    "                if statistical_communities[cl][i] == c:\n",
    "                    temp.append(nodes[i])\n",
    "                    \n",
    "            stat_communities[cl][c] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus Community on a group of networks\n",
    "\n",
    "For each network, Louvain community detection is performed ten times. By evaluating the different partitionings results for all networks in a group, a consensus is estimated based on clustering.consensus_clustering(), as explained in more detail in the Network clustering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus = {}\n",
    "\n",
    "for cl in clusters_networks.keys():\n",
    "    cons = ga.pattern_matching.get_consensus_community(clusters_networks[cl], nodes,  rep_network=10, threshold=0.75)\n",
    "    \n",
    "    consensus[cl] = cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the communities can be functionally enriched and compared between the clusters.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
