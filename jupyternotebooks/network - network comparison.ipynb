{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphAlgorithms as ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example file, we want to compare two gene networks (for example one representing a control and the other a treated sample; when using the example data two networks treated by different drugs are compared) in order to investigate if specific nodes(genes) or gene areas are changing (and therefore can be considered affected by a treatment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location where the raw data files are stored, it is set to run from the installation folder\n",
    "#- if applicable please CHANGE or CHANGE to the location of your networks\n",
    "\n",
    "graph_location = \"../networks/edgelists/\"\n",
    "\n",
    "#location where output should be saved\n",
    "#Please set location\n",
    "location = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step of the pipeline consists in loading the chosen data set.\n",
    "You can store your networks in any common format, however the xx package requires that the networks are provided as NetworkX Graph objects (refer to its documentation for detailed instructions). Moreover, the networks should be weighted: if you have an unweighted network, then assign all edges the same edge weight. The package assumes \"weight\" to be the default edge weight label, but this can be set when needed.\n",
    "\n",
    "An example on how to pre-process a network, stored as an edgelist, is provided below. Different loading and storing examples are provided in the \"import and export of networks\" jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = []\n",
    "networks_graphs = []\n",
    "cnt = 0\n",
    "print(\"load networks\")\n",
    "#gets all files located in the specified folder that end on .edgelist\n",
    "#CHANGE the ending if your files end differently\n",
    "for path in glob.glob(graph_location +\"*.edgelist\"):\n",
    "    if cnt < 2:\n",
    "        #you can specify that only part of the file name should be used as network name for later identification\n",
    "        name =  path.split(\"/\")[-1].replace(\".rds.edgelist\", \"\")\n",
    "\n",
    "\n",
    "        #read the edgelist file as a dataframe\n",
    "        fh = pd.read_csv(path, sep=\"\\t\")\n",
    "        #convert it into a NetworkX graph G and specify the column names of the node pairs\n",
    "        G=nx.from_pandas_edgelist(fh, \"V1\", \"V2\")\n",
    "\n",
    "        #if you have an unweighted network assign all edges the same edge weight - here a value of 1 is assigned\n",
    "        for u, v, d in G.edges(data=True):\n",
    "            d['weight'] = 1\n",
    "\n",
    "\n",
    "        #save the graph objects to a list (only suitable if small networks are processed)\n",
    "        #this is the main objects used for the examples below, which contains all networks\n",
    "        networks_graphs.append(G)\n",
    "        labels.append(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"loaded\", name)\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networkX graph object is converted into a list of lists format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ga.get_node_similarity.preprocess_graph(networks_graphs, attribute=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: If multiple networks are provided, get the union of nodes between them in order to ensure that all node names are mapped to the correct IDs (if this transformation is applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get union of nodes\n",
    "\n",
    "nodes = []\n",
    "for net in networks_graphs:\n",
    "    for node in net.nodes():\n",
    "        if node not in nodes:\n",
    "            nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapp node names to ID (this is mainly used for node & edge similarity functions)\n",
    "\n",
    "network_lists, mapping = ga.get_node_similarity.preprocess_node_list(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save mapping for later\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(location + \"node_id_mapping_network_network.pckl\", \"wb\") as f:\n",
    "    pickle.dump(mapping, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: create reversed mapping object\n",
    "\n",
    "reverse_mapping = ga.distances.node_edge_similarities.reverse_node_edge_mapping(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes\n",
    "\n",
    "The networks are compared based on different centrality measures (how the node location in the network changes) ato estimate which nodes are the most similar or different w.r.t. their network position.\n",
    "\n",
    "The centrality ranks are also used in the Network clustering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort nodes after the selected attributes\n",
    "\n",
    "sorted_nodes = []\n",
    "\n",
    "for graph in networks_graphs:\n",
    "    temp = ga.distances.node_edge_similarities.sort_node_list(graph, mapping, degree_centrality=True, closeness_centrality=True, betweenness=True, k=None, as_str=False)\n",
    "    \n",
    "    sorted_nodes.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we convert the output, which is a Python dict into a dataframe to make it more human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_ids = list(mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(mapping_ids, \n",
    "               columns =['Mapping ID']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the reversed mapping IDS (original node IDs - in the example networks they are Entrez IDs)\n",
    "entrez = []\n",
    "for g in mapping_ids:\n",
    "    entrez.append(reverse_mapping[g])\n",
    "df[\"Entrez IDs\"] = entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sorted_nodes)):\n",
    "    item = sorted_nodes[i][0]\n",
    "    for key in item.keys():\n",
    "        #ignore \"degree\" key, since it has not been calculated. We are using degree centrality instead.\n",
    "        #Adjust to your selected parameters\n",
    "        if key != \"degree\":\n",
    "            temp = []\n",
    "            for g in mapping_ids:\n",
    "                for xx in range(len(item[key])):\n",
    "                    if item[key][xx] == g:\n",
    "                        temp.append(xx)\n",
    "                \n",
    "            #add to dataframe\n",
    "            #since the results are in the same order as the network labels \n",
    "            #we can use the network label directly as column heading\n",
    "            df[labels[i]+\" Ranking \" + key] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display the dataframe\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in knowing which genes change the most between the networks with regards to their network position. Therefore we are going to estimate the rank difference of the median ranks. \n",
    "This can be done for any of the other parameters as well, if it is needed for your analysis in the same way.Please refer to the functions documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = []\n",
    "\n",
    "for g in mapping_ids:\n",
    "    \n",
    "    val1 = df.loc[df[\"Mapping ID\"] == g][labels[0]+\" Ranking average_median\"].to_list()[0]\n",
    "    \n",
    "    val2 = df.loc[df[\"Mapping ID\"] == g][labels[1]+\" Ranking average_median\"].to_list()[0]\n",
    "    \n",
    "    change.append(abs(val1-val2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_change = pd.DataFrame(list(zip(mapping_ids, entrez, change, df[labels[0]+\" Ranking average_median\"].to_list(), df[labels[1]+\" Ranking average_median\"].to_list())), \n",
    "               columns =['Mapping ID', 'Entrez IDs', 'Absolute Ranking Difference', labels[0]+' Ranking average_median', labels[1]+' Ranking average_median' ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sort the dataframe for easier visualization/ analysis\n",
    "\n",
    "df_change = df_change.sort_values(by =[\"Absolute Ranking Difference\"], axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we inspect the top 20 genes (which network position is the most affected between the compared networks). Adjust the value if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_change.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we inspect the bottom 20 genes (which network position changes the least between the two networks). Adjust the value if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_change.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges\n",
    "\n",
    "We now evaluate which edges are common in the two networks, which edges are unique and finally, which edges network position changes the most. The latter is estimated through betweenness estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the edge betweenness scores and assign them to the graph objects\n",
    "\n",
    "print(\"sort edges after edge betweenness\")\n",
    "bet = []\n",
    "graphs_with_betweenness = []\n",
    "for net in networks_graphs:\n",
    "    edges_betweenness = nx.edge_betweenness_centrality(net)\n",
    "    bet.append(edges_betweenness)\n",
    "    #write as new attribute to graph\n",
    "    temp = nx.set_edge_attributes(net, edges_betweenness, \"betweenness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous section the networks are converted to a list of list format and each edge is getting a unique ID assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = ga.get_edge_similarity.preprocess_graph(networks_graphs, attribute=\"betweenness\")\n",
    "\n",
    "print(\"map edges to id\")\n",
    "\n",
    "network_lists, mapping = ga.get_edge_similarity.preprocess_edge_list(networks)\n",
    "\n",
    "with open(location + \"edge_id_mapping_network_network.pckl\", \"wb\") as f:\n",
    "    pickle.dump(mapping, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_mapping = ga.distances.node_edge_similarities.reverse_node_edge_mapping(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shared edges are retrieved. The function returns a dictionary data format, where key is mapped edge ID and value is list of network names this edge is present in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared = ga.distances.node_edge_similarities.compute_shared_layers(network_lists, labels, is_file=False, in_async=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is converted into a dataframe for easier inspection of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(reverse_mapping.values())\n",
    "edge_mapped_IDs = list(reverse_mapping.keys())\n",
    "\n",
    "df = pd.DataFrame(list(zip(edges, edge_mapped_IDs)), \n",
    "               columns =['Edges', 'Mapping ID']) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    temp = []\n",
    "    for i in edge_mapped_IDs:\n",
    "        if label in shared[i]:\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "            \n",
    "    df[\"In \"+label] = temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the dataframe\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shared edges are retrieved and stored in a dataframe for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_df = df.loc[(df[\"In \"+labels[0]] == 1) & (df[\"In \"+labels[1]] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique edges are retrieved and stored in a dataframe for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = df.loc[((df[\"In \"+labels[0]] == 1) & (df[\"In \"+labels[1]] == 0)) | ((df[\"In \"+labels[0]] == 0) & (df[\"In \"+labels[1]] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node areas/ connectivity\n",
    "\n",
    "Hereafter we evaluate wheter nodes are connected in a similar way among the two networks, as well as if there are differences among node areas. In order to do this, we will make use of the random walks method, as already shown in the network clustering example file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random walks\n",
    "\n",
    "For each common node in the two networks, random walks are performed and their similarity in visited nodes is compared. This allows to identify the most similar/ dissimilar node areas.\n",
    "\n",
    "For each node, random walks of size 5 are performed by its degree number of times. A smaller walk size \"scans\" a smaller area around the starting node.Number of steps and number of walkers can be increased/decreased according to the experimental purposes (and memory availability). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performed_walks = ga.get_walk_distances.helper_walks(networks_graphs, nodes, labels, steps=5, number_of_walks=1, degree=True, probabilistic=False, weight =\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are estimating for each starting node how often surrounding nodes/ edges have been visit with respect to all the visited nodes/ edges. Depending on your network sizes and selected nodes this can be quite memory intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_counts, edge_counts, nodes_frc, edges_frc = ga.get_walk_distances.helper_get_counts(labels, networks_graphs, performed_walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to estimate network similarities based on the visited nodes. For each network pair, kendall rank correlation is calculated (of the top 20 nodes; adjust this value as needed) for the same starting node. The mean correlation value of all same node pairs for a network pair is estimated as well as the individual values are calculated and returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_edges, results_nodes, results_edges_p, results_nodes_p, results_edges_all, results_nodes_all, results_edges_p_all, results_nodes_p_all = ga.get_walk_distances.helper_walk_sim(networks_graphs, performed_walks, nodes, labels, top=20, undirected=False, return_all = True, nodes_ranked=nodes_frc, edges_ranked=edges_frc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are converted into a dataframe for inspection and the top and bottom 20 nodes are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(list(zip(nodes, results_nodes_all[(labels[0], labels[1])])), \n",
    "               columns =['Entrez ID', 'Correlation']) \n",
    "\n",
    "#dataframe is sorted after correlation\n",
    "\n",
    "df = df.sort_values(by =[\"Correlation\"], axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community/ Module detection\n",
    "\n",
    "We will detect modules in the graphs and map the previously identified similar/ dissimilar areas to them.\n",
    "Here we will only use a simple community detection method. For more algorithms, evaluation and ensembl methods please refer to the Community example file.\n",
    "\n",
    "For the example the walktrap algorithm is used, which is based on non probabilistic random walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "communities = []\n",
    "\n",
    "for graph in networks_graphs:\n",
    "    c = ga.communities.walktrap(graph, return_object=False)\n",
    "    #convert into another format\n",
    "    con = ga.communities.convert_communities(c)\n",
    "    \n",
    "    communities.append(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar are the detected communities/ modules w.r.t their nodes?\n",
    "\n",
    "To answer this we transform each community into a subgraph and compare their nodes (if they have at least 1 edge).\n",
    "For similar modules the edges can be compared as well. For this refer to the first sections of the network clustering jupyter notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = []\n",
    "com_labels = []\n",
    "for i in range(len(communities)):\n",
    "    com = communities[i]\n",
    "    graph = networks_graphs[i]\n",
    "    \n",
    "    for k in com.keys():\n",
    "        if len(graph.subgraph(com[k]).edges()) > 1:\n",
    "            subgraphs.append(graph.subgraph(com[k]))\n",
    "       \n",
    "            com_labels.append(labels[i]+\"_\"+str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the same functions as applied in the Nodes section in the Network clustering notebook. For explanations refer to this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_networks = ga.get_node_similarity.preprocess_graph(subgraphs, attribute=\"weight\")\n",
    "\n",
    "sub_network_lists, sub_mapping = ga.get_node_similarity.preprocess_node_list(sub_networks)\n",
    "\n",
    "with open(location + \"node_id_mapping_subgraphs.pckl\", \"wb\") as f:\n",
    "    pickle.dump(sub_mapping, f, protocol=4)\n",
    "    \n",
    "sorted_nodes, shared_nodes, binary, centrality_values = ga.get_node_similarity.sort_list_and_get_shared(sub_network_lists, sub_mapping, subgraphs, com_labels, degree_centrality=True, closeness_centrality=True, betweenness=True, degree=False, in_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jd, per = ga.node_edge_similarities.shared_elements_multiple(sub_network_lists, labels=com_labels, percentage=True, jaccard=True, jaccard_similarity=False, in_async=False, is_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the communities in the different networks contain similar nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))  \n",
    "\n",
    "sns.heatmap(jd, annot=False, ax=ax, xticklabels=com_labels, yticklabels=com_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))  \n",
    "\n",
    "sns.heatmap(per, annot=False, ax=ax, xticklabels=com_labels, yticklabels=com_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
